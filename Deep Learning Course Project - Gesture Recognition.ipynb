{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##         Deep Learning Course Project - Gesture Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote. \n",
    "\n",
    "The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
    "\n",
    "Thumbs up:  Increase the volume\n",
    "Thumbs down: Decrease the volume\n",
    "Left swipe: 'Jump' backwards 10 seconds\n",
    "Right swipe: 'Jump' forward 10 seconds  \n",
    "Stop: Pause the movie\n",
    "\n",
    "Each video is a sequence of 30 frames (or images).\n",
    "\n",
    "And here we are using 2 architecture - 3D CNN and a CNN-RNN based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the libraries which might be required in the model\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing all the libraries which might be required in the model\n",
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all the training and validation datasets\n",
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "nb_rows = 120   # X dimension of the image\n",
    "nb_cols = 120   # Y dimesnion of the image\n",
    "nb_frames = 30  # lenght of the video frames\n",
    "nb_channel = 3 # numbe rof channels in images 3 for color(RGB) and 1 for Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate a random affine transform on the image\n",
    "def get_random_affine():\n",
    "    dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data resizing - Resizing all the images, so we can have all the images in a specific size\n",
    "def crop_resize_img(img):\n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        img=img[0:120,10:150]\n",
    "    resized_image = imresize(img, (nb_rows,nb_cols))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to normalise the data\n",
    "def normalize_data(data):\n",
    "    return data/127.5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to initialize all the batch image data and labels\n",
    "def init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size, nb_frames, nb_rows, nb_cols, nb_channel)) \n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to do the data Augmentation, and prepare the data for further processes in modeling\n",
    "def data_augmentation(source_path, folder_list, batch_num, batch_size, t,validation):\n",
    "    \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augumented batch data with affine transformation\n",
    "    batch_data_aug,batch_labels_aug = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augmented batch data with horizontal flip\n",
    "    batch_data_flip,batch_labels_flip = init_batch_data(batch_size)\n",
    "    \n",
    "    #create a list of image numbers you want to use for a particular video using full frames\n",
    "    img_idx = [x for x in range(0, nb_frames)] \n",
    "\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        # read all the images in the folder\n",
    "        imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "        # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "        M = get_random_affine()\n",
    "        \n",
    "        #  Iterate over the frames/images of a folder to read them in\n",
    "        for idx, item in enumerate(img_idx): \n",
    "            image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Cropping non symmetric frames\n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                image=image[0:120,20:140]\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes   \n",
    "            resized = cv2.resize(image, (nb_rows,nb_cols), interpolation = cv2.INTER_AREA)\n",
    "            #Normal data\n",
    "            batch_data[folder,idx] = (resized)\n",
    "            \n",
    "            #Data with affine transformation\n",
    "            batch_data_aug[folder,idx] = (cv2.warpAffine(resized, M, (resized.shape[0], resized.shape[1])))\n",
    "            \n",
    "            # Data with horizontal flip\n",
    "            batch_data_flip[folder,idx]= np.flip(resized,1)\n",
    "\n",
    "        batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "        # Labeling data with horizobtal flip, right swipe becomes left swipe and viceversa\n",
    "        if int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==0:\n",
    "                    batch_labels_flip[folder, 1] = 1\n",
    "        elif int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==1:\n",
    "                    batch_labels_flip[folder, 0] = 1\n",
    "                    \n",
    "        else:\n",
    "                    batch_labels_flip[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "                  \n",
    "    \n",
    "    batch_data_final = np.append(batch_data, batch_data_aug, axis = 0)\n",
    "    batch_data_final = np.append(batch_data_final, batch_data_flip, axis = 0)\n",
    "\n",
    "    batch_labels_final = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "    batch_labels_final = np.append(batch_labels_final, batch_labels_flip, axis = 0)\n",
    "    \n",
    "    if validation:\n",
    "        batch_data_final=batch_data\n",
    "        batch_labels_final= batch_labels\n",
    "        \n",
    "    return batch_data_final,batch_labels_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well \n",
    "## as create a batch of video frames. \n",
    "\n",
    "def generator(source_path, folder_list, batch_size, validation=False):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "            yield data_augmentation(source_path, folder_list, batch, batch_size, t,validation)\n",
    "            \n",
    "\n",
    "        \n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield data_augmentation(source_path, folder_list, batch, batch_size, t,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "# Frames = 30\n"
     ]
    }
   ],
   "source": [
    "# storing the train and validation paths and storing the train and validation sequesnces length\n",
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = './Project_data/train'\n",
    "val_path = './Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 20 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)\n",
    "num_classes = 5\n",
    "print('# Frames =', nb_frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 3D CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the libraries required for 3D CNN model and also building an 3D CNN model here\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(nb_frames,nb_rows,nb_cols,nb_channel)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_17 (Conv3D)           (None, 16, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 16, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 8, 60, 60, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 8, 60, 60, 16)     3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 60, 60, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 8, 60, 60, 16)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 4, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 4, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 4, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 2, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 2, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# using the right optimiser and also compling the model\n",
    "\n",
    "optimiser = Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 1 -- Framesize = 30, batch_size = 10, epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation \n",
    "\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the train and validation generator\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_1 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_1):\n",
    "    os.mkdir(model_name_1)\n",
    "        \n",
    "filepath = model_name_1 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 864101\n",
      "Source path =  ./Project_data/val ; batch size =Source path =  ./Project_data/train  10\n",
      "; batch size = 10\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 192s 3s/step - loss: 1.6936 - categorical_accuracy: 0.2783 - val_loss: 1.4282 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2413_34_13.508854/model-00001-1.69240-0.28004-1.42818-0.39000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 1.4484 - categorical_accuracy: 0.3765 - val_loss: 1.3240 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2413_34_13.508854/model-00002-1.44836-0.37645-1.32402-0.53000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 29s 429ms/step - loss: 1.4268 - categorical_accuracy: 0.3947 - val_loss: 1.3466 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2413_34_13.508854/model-00003-1.42676-0.39469-1.34661-0.49000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 28s 413ms/step - loss: 1.2582 - categorical_accuracy: 0.5058 - val_loss: 1.0745 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2413_34_13.508854/model-00004-1.25825-0.50580-1.07454-0.51000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 28s 411ms/step - loss: 1.0737 - categorical_accuracy: 0.5390 - val_loss: 1.0130 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2413_34_13.508854/model-00005-1.07367-0.53897-1.01299-0.59000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 0.9854 - categorical_accuracy: 0.6169 - val_loss: 0.9148 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2413_34_13.508854/model-00006-0.98542-0.61692-0.91476-0.67000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 28s 418ms/step - loss: 0.8616 - categorical_accuracy: 0.6799 - val_loss: 1.1559 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2413_34_13.508854/model-00007-0.86161-0.67993-1.15587-0.55000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 0.9210 - categorical_accuracy: 0.6468 - val_loss: 0.7004 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2413_34_13.508854/model-00008-0.92099-0.64677-0.70039-0.74000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.7107 - categorical_accuracy: 0.7313 - val_loss: 0.7221 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2413_34_13.508854/model-00009-0.71073-0.73134-0.72214-0.67000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 28s 418ms/step - loss: 0.7718 - categorical_accuracy: 0.6932 - val_loss: 0.7976 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2413_34_13.508854/model-00010-0.77182-0.69320-0.79763-0.70000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.7257 - categorical_accuracy: 0.7247 - val_loss: 1.1080 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2413_34_13.508854/model-00011-0.72572-0.72471-1.10801-0.56000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 0.5429 - categorical_accuracy: 0.7778 - val_loss: 0.5907 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2413_34_13.508854/model-00012-0.54286-0.77778-0.59072-0.74000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.5025 - categorical_accuracy: 0.8027 - val_loss: 0.6700 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2413_34_13.508854/model-00013-0.50254-0.80265-0.67005-0.75000.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 0.5790 - categorical_accuracy: 0.7828 - val_loss: 0.6020 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2413_34_13.508854/model-00014-0.57904-0.78275-0.60202-0.78000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.4892 - categorical_accuracy: 0.8093 - val_loss: 0.4639 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2413_34_13.508854/model-00015-0.48916-0.80929-0.46390-0.79000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.4193 - categorical_accuracy: 0.8474 - val_loss: 0.4693 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2413_34_13.508854/model-00016-0.41929-0.84743-0.46927-0.80000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 29s 426ms/step - loss: 0.4215 - categorical_accuracy: 0.8474 - val_loss: 0.4816 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2413_34_13.508854/model-00017-0.42155-0.84743-0.48160-0.80000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 28s 418ms/step - loss: 0.3166 - categorical_accuracy: 0.8789 - val_loss: 0.5180 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2413_34_13.508854/model-00018-0.31664-0.87894-0.51800-0.76000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.4422 - categorical_accuracy: 0.8391 - val_loss: 0.4615 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2413_34_13.508854/model-00019-0.44219-0.83914-0.46148-0.83000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 0.3478 - categorical_accuracy: 0.8773 - val_loss: 0.4373 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2413_34_13.508854/model-00020-0.34785-0.87728-0.43735-0.81000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f137f630390>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# giving right number of Epoch and fiting the model\n",
    "\n",
    "num_epochs = 20\n",
    "print(\"Total Params:\", model.count_params())\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 2 -- Framesize = 30, batch_size = 30, epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing a new batch value\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and validation generator\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_2 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_2):\n",
    "    os.mkdir(model_name_2)\n",
    "        \n",
    "filepath = model_name_2 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 864101\n",
      "Source path =  ./Project_data/val ; batch size = 30\n",
      "Source path =  ./Project_data/train ; batch size = 30\n",
      "Epoch 1/30\n",
      "23/23 [==============================] - 90s 4s/step - loss: 0.3367 - categorical_accuracy: 0.8721 - val_loss: 0.3769 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2413_34_13.508854/model-00001-0.33448-0.87582-0.37691-0.85000.h5\n",
      "Epoch 2/30\n",
      "23/23 [==============================] - 9s 370ms/step - loss: 0.4239 - categorical_accuracy: 0.8986 - val_loss: 0.4758 - val_categorical_accuracy: 0.8250\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2413_34_13.508854/model-00002-0.42393-0.89855-0.47576-0.82500.h5\n",
      "Epoch 3/30\n",
      "23/23 [==============================] - 9s 382ms/step - loss: 0.3357 - categorical_accuracy: 0.8647 - val_loss: 0.4443 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2413_34_13.508854/model-00003-0.33569-0.86473-0.44430-0.80000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 4/30\n",
      "23/23 [==============================] - 9s 398ms/step - loss: 0.2973 - categorical_accuracy: 0.8889 - val_loss: 0.3406 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2413_34_13.508854/model-00004-0.29728-0.88889-0.34057-0.85000.h5\n",
      "Epoch 5/30\n",
      "23/23 [==============================] - 10s 432ms/step - loss: 0.3307 - categorical_accuracy: 0.8792 - val_loss: 0.4814 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2413_34_13.508854/model-00005-0.33073-0.87923-0.48136-0.80000.h5\n",
      "Epoch 6/30\n",
      "23/23 [==============================] - 10s 416ms/step - loss: 0.3658 - categorical_accuracy: 0.8696 - val_loss: 0.3682 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2413_34_13.508854/model-00006-0.36579-0.86957-0.36825-0.85000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 7/30\n",
      "23/23 [==============================] - 10s 426ms/step - loss: 0.3498 - categorical_accuracy: 0.8986 - val_loss: 0.2716 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2413_34_13.508854/model-00007-0.34981-0.89855-0.27160-0.90000.h5\n",
      "Epoch 8/30\n",
      "23/23 [==============================] - 10s 422ms/step - loss: 0.3632 - categorical_accuracy: 0.8502 - val_loss: 0.4689 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2413_34_13.508854/model-00008-0.36322-0.85024-0.46890-0.85000.h5\n",
      "Epoch 9/30\n",
      "23/23 [==============================] - 10s 428ms/step - loss: 0.3067 - categorical_accuracy: 0.9034 - val_loss: 0.5278 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2413_34_13.508854/model-00009-0.30669-0.90338-0.52783-0.80000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 10/30\n",
      "23/23 [==============================] - 10s 436ms/step - loss: 0.3701 - categorical_accuracy: 0.8647 - val_loss: 0.4457 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2413_34_13.508854/model-00010-0.37014-0.86473-0.44566-0.85000.h5\n",
      "Epoch 11/30\n",
      "23/23 [==============================] - 10s 432ms/step - loss: 0.2959 - categorical_accuracy: 0.9130 - val_loss: 0.4134 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2413_34_13.508854/model-00011-0.29592-0.91304-0.41340-0.85000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 12/30\n",
      "23/23 [==============================] - 9s 400ms/step - loss: 0.2668 - categorical_accuracy: 0.9227 - val_loss: 0.4534 - val_categorical_accuracy: 0.8250\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2413_34_13.508854/model-00012-0.26680-0.92271-0.45338-0.82500.h5\n",
      "Epoch 13/30\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.3151 - categorical_accuracy: 0.8696 - val_loss: 0.3798 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2413_34_13.508854/model-00013-0.31511-0.86957-0.37978-0.90000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 14/30\n",
      "23/23 [==============================] - 10s 417ms/step - loss: 0.3321 - categorical_accuracy: 0.8744 - val_loss: 0.3511 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2413_34_13.508854/model-00014-0.33212-0.87440-0.35109-0.90000.h5\n",
      "Epoch 15/30\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.3049 - categorical_accuracy: 0.8647 - val_loss: 0.4009 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2413_34_13.508854/model-00015-0.30489-0.86473-0.40088-0.80000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 16/30\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.3325 - categorical_accuracy: 0.8551 - val_loss: 0.5402 - val_categorical_accuracy: 0.8250\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2413_34_13.508854/model-00016-0.33248-0.85507-0.54019-0.82500.h5\n",
      "Epoch 17/30\n",
      "23/23 [==============================] - 9s 400ms/step - loss: 0.3174 - categorical_accuracy: 0.8841 - val_loss: 0.4258 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2413_34_13.508854/model-00017-0.31744-0.88406-0.42576-0.87500.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 18/30\n",
      "23/23 [==============================] - 9s 388ms/step - loss: 0.2535 - categorical_accuracy: 0.9275 - val_loss: 0.4111 - val_categorical_accuracy: 0.8250\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2413_34_13.508854/model-00018-0.25351-0.92754-0.41112-0.82500.h5\n",
      "Epoch 19/30\n",
      "23/23 [==============================] - 10s 414ms/step - loss: 0.3124 - categorical_accuracy: 0.9130 - val_loss: 0.4881 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2413_34_13.508854/model-00019-0.31237-0.91304-0.48813-0.80000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 20/30\n",
      "23/23 [==============================] - 10s 435ms/step - loss: 0.2750 - categorical_accuracy: 0.8841 - val_loss: 0.3645 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2413_34_13.508854/model-00020-0.27504-0.88406-0.36453-0.90000.h5\n",
      "Epoch 21/30\n",
      "23/23 [==============================] - 10s 443ms/step - loss: 0.2302 - categorical_accuracy: 0.9227 - val_loss: 0.4384 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-05-2413_34_13.508854/model-00021-0.23018-0.92271-0.43844-0.85000.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 22/30\n",
      "23/23 [==============================] - 10s 421ms/step - loss: 0.2707 - categorical_accuracy: 0.9130 - val_loss: 0.2967 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-05-2413_34_13.508854/model-00022-0.27073-0.91304-0.29666-0.90000.h5\n",
      "Epoch 23/30\n",
      "23/23 [==============================] - 10s 442ms/step - loss: 0.4495 - categorical_accuracy: 0.8068 - val_loss: 0.3852 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-05-2413_34_13.508854/model-00023-0.44952-0.80676-0.38520-0.87500.h5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 24/30\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.3050 - categorical_accuracy: 0.8937 - val_loss: 0.6258 - val_categorical_accuracy: 0.7250\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-05-2413_34_13.508854/model-00024-0.30501-0.89372-0.62581-0.72500.h5\n",
      "Epoch 25/30\n",
      "23/23 [==============================] - 10s 435ms/step - loss: 0.2933 - categorical_accuracy: 0.8889 - val_loss: 0.4751 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-05-2413_34_13.508854/model-00025-0.29335-0.88889-0.47514-0.87500.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 26/30\n",
      "23/23 [==============================] - 10s 423ms/step - loss: 0.3795 - categorical_accuracy: 0.8406 - val_loss: 0.3475 - val_categorical_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: saving model to model_init_2020-05-2413_34_13.508854/model-00026-0.37947-0.84058-0.34749-0.87500.h5\n",
      "Epoch 27/30\n",
      "23/23 [==============================] - 10s 415ms/step - loss: 0.2933 - categorical_accuracy: 0.8889 - val_loss: 0.5382 - val_categorical_accuracy: 0.8250\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-05-2413_34_13.508854/model-00027-0.29334-0.88889-0.53816-0.82500.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 28/30\n",
      "23/23 [==============================] - 9s 407ms/step - loss: 0.2597 - categorical_accuracy: 0.9227 - val_loss: 0.3837 - val_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-05-2413_34_13.508854/model-00028-0.25968-0.92271-0.38369-0.87500.h5\n",
      "Epoch 29/30\n",
      "23/23 [==============================] - 10s 444ms/step - loss: 0.3250 - categorical_accuracy: 0.8792 - val_loss: 0.3619 - val_categorical_accuracy: 0.8250\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-05-2413_34_13.508854/model-00029-0.32504-0.87923-0.36186-0.82500.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 30/30\n",
      "23/23 [==============================] - 9s 401ms/step - loss: 0.2360 - categorical_accuracy: 0.9034 - val_loss: 0.3499 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-05-2413_34_13.508854/model-00030-0.23604-0.90338-0.34991-0.90000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f135fb1c9b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using new epoch size and fiting the model\n",
    "num_epochs = 30\n",
    "print(\"Total Params:\", model.count_params())\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-3 -- Framesize = 30, batch_size = 20, epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new batch size\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and validation generators\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating checkpoint\n",
    "model_name_3 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_3):\n",
    "    os.mkdir(model_name_3)\n",
    "        \n",
    "filepath = model_name_3 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 864101\n",
      "Source path =  ./Project_data/valSource path =  ./Project_data/train Epoch 1/20\n",
      " ; batch size = ; batch size = 20\n",
      "20\n",
      "34/34 [==============================] - 90s 3s/step - loss: 0.2964 - categorical_accuracy: 0.8940 - val_loss: 0.4249 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2413_34_13.508854/model-00001-0.30362-0.89140-0.42494-0.85000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.2968 - categorical_accuracy: 0.9020 - val_loss: 0.4254 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2413_34_13.508854/model-00002-0.29679-0.90196-0.42536-0.85000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 16s 476ms/step - loss: 0.3265 - categorical_accuracy: 0.8725 - val_loss: 0.4259 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2413_34_13.508854/model-00003-0.32653-0.87255-0.42586-0.85000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.3021 - categorical_accuracy: 0.8824 - val_loss: 0.4260 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2413_34_13.508854/model-00004-0.30215-0.88235-0.42602-0.85000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 15s 444ms/step - loss: 0.2856 - categorical_accuracy: 0.9020 - val_loss: 0.4269 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2413_34_13.508854/model-00005-0.28561-0.90196-0.42690-0.85000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 15s 431ms/step - loss: 0.3436 - categorical_accuracy: 0.8497 - val_loss: 0.4261 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2413_34_13.508854/model-00006-0.34363-0.84967-0.42611-0.85000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 15s 440ms/step - loss: 0.2811 - categorical_accuracy: 0.9085 - val_loss: 0.4249 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2413_34_13.508854/model-00007-0.28105-0.90850-0.42492-0.85000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 15s 434ms/step - loss: 0.2758 - categorical_accuracy: 0.9020 - val_loss: 0.4246 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2413_34_13.508854/model-00008-0.27579-0.90196-0.42462-0.85000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 15s 432ms/step - loss: 0.2938 - categorical_accuracy: 0.8922 - val_loss: 0.4251 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2413_34_13.508854/model-00009-0.29382-0.89216-0.42509-0.85000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 16s 458ms/step - loss: 0.3828 - categorical_accuracy: 0.8431 - val_loss: 0.4257 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2413_34_13.508854/model-00010-0.38277-0.84314-0.42570-0.85000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 15s 455ms/step - loss: 0.3501 - categorical_accuracy: 0.8529 - val_loss: 0.4251 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2413_34_13.508854/model-00011-0.35008-0.85294-0.42511-0.85000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 15s 450ms/step - loss: 0.3300 - categorical_accuracy: 0.8627 - val_loss: 0.4249 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2413_34_13.508854/model-00012-0.32997-0.86275-0.42486-0.85000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 15s 435ms/step - loss: 0.2765 - categorical_accuracy: 0.9085 - val_loss: 0.4255 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2413_34_13.508854/model-00013-0.27646-0.90850-0.42548-0.85000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 15s 440ms/step - loss: 0.2621 - categorical_accuracy: 0.9052 - val_loss: 0.4255 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2413_34_13.508854/model-00014-0.26210-0.90523-0.42552-0.85000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 15s 454ms/step - loss: 0.3412 - categorical_accuracy: 0.8824 - val_loss: 0.4250 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2413_34_13.508854/model-00015-0.34120-0.88235-0.42499-0.85000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 15s 446ms/step - loss: 0.3222 - categorical_accuracy: 0.8693 - val_loss: 0.4248 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2413_34_13.508854/model-00016-0.32224-0.86928-0.42480-0.85000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 16s 461ms/step - loss: 0.2460 - categorical_accuracy: 0.9281 - val_loss: 0.4249 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2413_34_13.508854/model-00017-0.24600-0.92810-0.42494-0.85000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 15s 437ms/step - loss: 0.2866 - categorical_accuracy: 0.8889 - val_loss: 0.4258 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2413_34_13.508854/model-00018-0.28657-0.88889-0.42584-0.85000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 16s 460ms/step - loss: 0.3299 - categorical_accuracy: 0.8725 - val_loss: 0.4266 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2413_34_13.508854/model-00019-0.32990-0.87255-0.42661-0.85000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 14s 424ms/step - loss: 0.3586 - categorical_accuracy: 0.8758 - val_loss: 0.4259 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2413_34_13.508854/model-00020-0.35863-0.87582-0.42589-0.85000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f135fb0be48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using new epoch value and fiting the model\n",
    "num_epochs = 20\n",
    "\n",
    "print(\"Total Params:\", model.count_params())\n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 -- Framesize = 20, batch_size = 10, epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new batch size\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a checkpoint\n",
    "model_name_4 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_4):\n",
    "    os.mkdir(model_name_4)\n",
    "        \n",
    "filepath = model_name_4 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Frames = 20\n"
     ]
    }
   ],
   "source": [
    "print('# Frames =', nb_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 864101\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 61s 905ms/step - loss: 1.6875 - categorical_accuracy: 0.2775 - val_loss: 1.3339 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2414_12_25.543099/model-00001-1.69698-0.27221-1.33387-0.44000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 19s 276ms/step - loss: 1.4163 - categorical_accuracy: 0.4063 - val_loss: 1.5128 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2414_12_25.543099/model-00002-1.41628-0.40630-1.51276-0.40000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 18s 274ms/step - loss: 1.3418 - categorical_accuracy: 0.4776 - val_loss: 1.1230 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2414_12_25.543099/model-00003-1.34181-0.47761-1.12298-0.55000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 18s 269ms/step - loss: 1.3953 - categorical_accuracy: 0.4063 - val_loss: 1.3288 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2414_12_25.543099/model-00004-1.39530-0.40630-1.32884-0.38000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 19s 283ms/step - loss: 1.2018 - categorical_accuracy: 0.5638 - val_loss: 1.8173 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2414_12_25.543099/model-00005-1.20183-0.56385-1.81728-0.30000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 18s 265ms/step - loss: 0.9078 - categorical_accuracy: 0.6235 - val_loss: 1.1178 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2414_12_25.543099/model-00006-0.90783-0.62355-1.11778-0.56000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 1.0124 - categorical_accuracy: 0.5771 - val_loss: 0.7973 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2414_12_25.543099/model-00007-1.01244-0.57711-0.79733-0.70000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 18s 268ms/step - loss: 0.9030 - categorical_accuracy: 0.6600 - val_loss: 0.9214 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2414_12_25.543099/model-00008-0.90299-0.66003-0.92141-0.60000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 18s 274ms/step - loss: 0.7922 - categorical_accuracy: 0.6700 - val_loss: 0.9176 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2414_12_25.543099/model-00009-0.79219-0.66998-0.91760-0.63000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 18s 270ms/step - loss: 0.7951 - categorical_accuracy: 0.6584 - val_loss: 0.7691 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2414_12_25.543099/model-00010-0.79511-0.65837-0.76907-0.72000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 19s 277ms/step - loss: 0.7869 - categorical_accuracy: 0.6833 - val_loss: 0.6215 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2414_12_25.543099/model-00011-0.78685-0.68325-0.62148-0.72000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 18s 266ms/step - loss: 0.6892 - categorical_accuracy: 0.7396 - val_loss: 0.6630 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2414_12_25.543099/model-00012-0.68920-0.73964-0.66302-0.71000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 19s 281ms/step - loss: 0.6005 - categorical_accuracy: 0.7330 - val_loss: 0.6383 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2414_12_25.543099/model-00013-0.60053-0.73300-0.63831-0.74000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 18s 275ms/step - loss: 0.5719 - categorical_accuracy: 0.7877 - val_loss: 0.6204 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2414_12_25.543099/model-00014-0.57188-0.78773-0.62042-0.76000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 18s 276ms/step - loss: 0.5723 - categorical_accuracy: 0.7794 - val_loss: 0.5069 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2414_12_25.543099/model-00015-0.57231-0.77944-0.50686-0.80000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 18s 265ms/step - loss: 0.5416 - categorical_accuracy: 0.7811 - val_loss: 0.5637 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2414_12_25.543099/model-00016-0.54163-0.78109-0.56372-0.83000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 19s 276ms/step - loss: 0.5522 - categorical_accuracy: 0.7745 - val_loss: 0.5116 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2414_12_25.543099/model-00017-0.55217-0.77446-0.51159-0.76000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 18s 268ms/step - loss: 0.5166 - categorical_accuracy: 0.7977 - val_loss: 0.4997 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2414_12_25.543099/model-00018-0.51662-0.79768-0.49973-0.77000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 18s 266ms/step - loss: 0.4598 - categorical_accuracy: 0.8308 - val_loss: 0.5381 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2414_12_25.543099/model-00019-0.45976-0.83085-0.53811-0.79000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 19s 278ms/step - loss: 0.5057 - categorical_accuracy: 0.7927 - val_loss: 0.4901 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2414_12_25.543099/model-00020-0.50573-0.79270-0.49010-0.84000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f135fed14e0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using new epoch value and fiting the model\n",
    "num_epochs = 20\n",
    "nb_frames = 20\n",
    "\n",
    "print(\"Total Params:\", model.count_params())\n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 5 -- Framesize = 30, batch_size = 20, epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some libraries and creating a new model by adding some new layers to the model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(nb_frames,nb_rows,nb_cols,nb_channel)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 15, 60, 60, 16)    6928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 887,605\n",
      "Trainable params: 887,461\n",
      "Non-trainable params: 144\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# using the adam optimiser\n",
    "optimiser = Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new batch size for a new architecture\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the checkpoint\n",
    "model_name_5 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_5):\n",
    "    os.mkdir(model_name_5)\n",
    "        \n",
    "filepath = model_name_5 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 887605\n",
      "Source path =  ./Project_data/val ; batch size = 30\n",
      "Source path =  ./Project_data/train ; batch size = 30\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - 155s 7s/step - loss: 1.5915 - categorical_accuracy: 0.2135 - val_loss: 1.5203 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2506_37_23.930997/model-00001-1.59304-0.21317-1.52031-0.19000.h5\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 11s 464ms/step - loss: 1.6011 - categorical_accuracy: 0.2899 - val_loss: 1.5904 - val_categorical_accuracy: 0.2750\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2506_37_23.930997/model-00002-1.60111-0.28986-1.59042-0.27500.h5\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 1.6218 - categorical_accuracy: 0.2512 - val_loss: 1.4853 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2506_37_23.930997/model-00003-1.62179-0.25121-1.48530-0.45000.h5\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.5841 - categorical_accuracy: 0.2415 - val_loss: 1.5011 - val_categorical_accuracy: 0.3250\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2506_37_23.930997/model-00004-1.58414-0.24155-1.50106-0.32500.h5\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 11s 464ms/step - loss: 1.5597 - categorical_accuracy: 0.2899 - val_loss: 1.3826 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2506_37_23.930997/model-00005-1.55971-0.28986-1.38265-0.50000.h5\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 1.5382 - categorical_accuracy: 0.3188 - val_loss: 1.5249 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2506_37_23.930997/model-00006-1.53818-0.31884-1.52486-0.37500.h5\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 1.4624 - categorical_accuracy: 0.3043 - val_loss: 1.3887 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2506_37_23.930997/model-00007-1.46242-0.30435-1.38869-0.40000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 1.3564 - categorical_accuracy: 0.4155 - val_loss: 1.4697 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2506_37_23.930997/model-00008-1.35637-0.41546-1.46970-0.30000.h5\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.3725 - categorical_accuracy: 0.4010 - val_loss: 1.5478 - val_categorical_accuracy: 0.1750\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2506_37_23.930997/model-00009-1.37250-0.40097-1.54775-0.17500.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 1.4227 - categorical_accuracy: 0.3816 - val_loss: 1.4859 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2506_37_23.930997/model-00010-1.42270-0.38164-1.48593-0.35000.h5\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.2781 - categorical_accuracy: 0.4251 - val_loss: 1.4631 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2506_37_23.930997/model-00011-1.27806-0.42512-1.46305-0.20000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 1.3065 - categorical_accuracy: 0.4396 - val_loss: 1.4647 - val_categorical_accuracy: 0.2750\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2506_37_23.930997/model-00012-1.30653-0.43961-1.46469-0.27500.h5\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 1.1406 - categorical_accuracy: 0.5459 - val_loss: 1.4381 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2506_37_23.930997/model-00013-1.14063-0.54589-1.43809-0.30000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.3337 - categorical_accuracy: 0.4589 - val_loss: 1.4117 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2506_37_23.930997/model-00014-1.33370-0.45894-1.41166-0.25000.h5\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 1.2266 - categorical_accuracy: 0.4396 - val_loss: 1.3230 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2506_37_23.930997/model-00015-1.22655-0.43961-1.32305-0.37500.h5\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 1.2671 - categorical_accuracy: 0.4106 - val_loss: 1.3331 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2506_37_23.930997/model-00016-1.26713-0.41063-1.33309-0.40000.h5\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.2755 - categorical_accuracy: 0.4638 - val_loss: 1.2404 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2506_37_23.930997/model-00017-1.27549-0.46377-1.24038-0.40000.h5\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.2186 - categorical_accuracy: 0.4734 - val_loss: 1.2587 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2506_37_23.930997/model-00018-1.21859-0.47343-1.25871-0.50000.h5\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 1.2995 - categorical_accuracy: 0.4444 - val_loss: 1.0598 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2506_37_23.930997/model-00019-1.29954-0.44444-1.05978-0.55000.h5\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 1.1627 - categorical_accuracy: 0.5169 - val_loss: 1.0649 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2506_37_23.930997/model-00020-1.16274-0.51691-1.06494-0.60000.h5\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.1340 - categorical_accuracy: 0.5121 - val_loss: 1.1208 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-05-2506_37_23.930997/model-00021-1.13395-0.51208-1.12077-0.50000.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 1.3366 - categorical_accuracy: 0.4348 - val_loss: 1.0411 - val_categorical_accuracy: 0.5750\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-05-2506_37_23.930997/model-00022-1.33663-0.43478-1.04112-0.57500.h5\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 1.1164 - categorical_accuracy: 0.5121 - val_loss: 1.1580 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-05-2506_37_23.930997/model-00023-1.11637-0.51208-1.15803-0.55000.h5\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.2570 - categorical_accuracy: 0.4203 - val_loss: 1.0200 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-05-2506_37_23.930997/model-00024-1.25697-0.42029-1.02000-0.62500.h5\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.3575 - categorical_accuracy: 0.4348 - val_loss: 1.0955 - val_categorical_accuracy: 0.5750\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-05-2506_37_23.930997/model-00025-1.35752-0.43478-1.09545-0.57500.h5\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 1.1074 - categorical_accuracy: 0.4928 - val_loss: 1.0188 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-05-2506_37_23.930997/model-00026-1.10744-0.49275-1.01883-0.62500.h5\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.2109 - categorical_accuracy: 0.5024 - val_loss: 1.0513 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-05-2506_37_23.930997/model-00027-1.21093-0.50242-1.05131-0.60000.h5\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 1.0558 - categorical_accuracy: 0.5169 - val_loss: 1.0975 - val_categorical_accuracy: 0.5250\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-05-2506_37_23.930997/model-00028-1.05576-0.51691-1.09749-0.52500.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.3832 - categorical_accuracy: 0.4058 - val_loss: 1.0117 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-05-2506_37_23.930997/model-00029-1.38320-0.40580-1.01167-0.62500.h5\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.1695 - categorical_accuracy: 0.5024 - val_loss: 1.0341 - val_categorical_accuracy: 0.5250\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-05-2506_37_23.930997/model-00030-1.16953-0.50242-1.03406-0.52500.h5\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.1243 - categorical_accuracy: 0.4396 - val_loss: 1.0675 - val_categorical_accuracy: 0.5250\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-05-2506_37_23.930997/model-00031-1.12434-0.43961-1.06753-0.52500.h5\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 1.3188 - categorical_accuracy: 0.4879 - val_loss: 1.1461 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-05-2506_37_23.930997/model-00032-1.31879-0.48792-1.14605-0.50000.h5\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 1.1026 - categorical_accuracy: 0.4686 - val_loss: 0.9183 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-05-2506_37_23.930997/model-00033-1.10259-0.46860-0.91829-0.62500.h5\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.2998 - categorical_accuracy: 0.4928 - val_loss: 1.0086 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-05-2506_37_23.930997/model-00034-1.29978-0.49275-1.00864-0.60000.h5\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.1587 - categorical_accuracy: 0.5459 - val_loss: 1.1933 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-05-2506_37_23.930997/model-00035-1.15871-0.54589-1.19327-0.45000.h5\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.3197 - categorical_accuracy: 0.3671 - val_loss: 0.9117 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00036: saving model to model_init_2020-05-2506_37_23.930997/model-00036-1.31965-0.36715-0.91173-0.62500.h5\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.1374 - categorical_accuracy: 0.5072 - val_loss: 0.9986 - val_categorical_accuracy: 0.5250\n",
      "\n",
      "Epoch 00037: saving model to model_init_2020-05-2506_37_23.930997/model-00037-1.13739-0.50725-0.99857-0.52500.h5\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.2453 - categorical_accuracy: 0.4879 - val_loss: 1.1280 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00038: saving model to model_init_2020-05-2506_37_23.930997/model-00038-1.24525-0.48792-1.12802-0.55000.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 1.1186 - categorical_accuracy: 0.4734 - val_loss: 0.9901 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00039: saving model to model_init_2020-05-2506_37_23.930997/model-00039-1.11860-0.47343-0.99010-0.45000.h5\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 1.1822 - categorical_accuracy: 0.5217 - val_loss: 1.0481 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00040: saving model to model_init_2020-05-2506_37_23.930997/model-00040-1.18218-0.52174-1.04805-0.60000.h5\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7aaa85ef0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new epochs and fiting the model\n",
    "num_epochs = 40\n",
    "\n",
    "print(\"Total Params:\", model.count_params())\n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 6 -- Framesize = 20, batch_size = 20, epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new batch size\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a checkpoint\n",
    "model_name_6 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_6):\n",
    "    os.mkdir(model_name_6)\n",
    "        \n",
    "filepath = model_name_6 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 864101\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/30\n",
      "34/34 [==============================] - 61s 2s/step - loss: 0.4294 - categorical_accuracy: 0.8362 - val_loss: 0.4819 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2414_12_25.543099/model-00001-0.42747-0.83761-0.48195-0.80000.h5\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - 10s 283ms/step - loss: 0.4935 - categorical_accuracy: 0.7974 - val_loss: 0.4786 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2414_12_25.543099/model-00002-0.49352-0.79739-0.47860-0.80000.h5\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - 11s 312ms/step - loss: 0.3994 - categorical_accuracy: 0.8595 - val_loss: 0.4849 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2414_12_25.543099/model-00003-0.39943-0.85948-0.48487-0.80000.h5\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - 11s 326ms/step - loss: 0.4127 - categorical_accuracy: 0.8105 - val_loss: 0.4832 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2414_12_25.543099/model-00004-0.41270-0.81046-0.48323-0.80000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - 10s 302ms/step - loss: 0.4843 - categorical_accuracy: 0.7941 - val_loss: 0.4822 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2414_12_25.543099/model-00005-0.48432-0.79412-0.48222-0.80000.h5\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - 11s 325ms/step - loss: 0.3609 - categorical_accuracy: 0.8693 - val_loss: 0.4809 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2414_12_25.543099/model-00006-0.36085-0.86928-0.48087-0.80000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - 10s 308ms/step - loss: 0.4624 - categorical_accuracy: 0.8366 - val_loss: 0.4787 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2414_12_25.543099/model-00007-0.46237-0.83660-0.47873-0.80000.h5\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - 10s 303ms/step - loss: 0.4035 - categorical_accuracy: 0.8595 - val_loss: 0.4778 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2414_12_25.543099/model-00008-0.40351-0.85948-0.47780-0.80000.h5\n",
      "Epoch 9/30\n",
      "34/34 [==============================] - 11s 316ms/step - loss: 0.5358 - categorical_accuracy: 0.8072 - val_loss: 0.4782 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2414_12_25.543099/model-00009-0.53583-0.80719-0.47822-0.80000.h5\n",
      "Epoch 10/30\n",
      "34/34 [==============================] - 11s 317ms/step - loss: 0.4898 - categorical_accuracy: 0.7974 - val_loss: 0.4794 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2414_12_25.543099/model-00010-0.48976-0.79739-0.47937-0.80000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 11/30\n",
      "34/34 [==============================] - 11s 326ms/step - loss: 0.3736 - categorical_accuracy: 0.8693 - val_loss: 0.4764 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2414_12_25.543099/model-00011-0.37359-0.86928-0.47643-0.79000.h5\n",
      "Epoch 12/30\n",
      "34/34 [==============================] - 10s 297ms/step - loss: 0.4127 - categorical_accuracy: 0.8595 - val_loss: 0.4759 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2414_12_25.543099/model-00012-0.41272-0.85948-0.47590-0.79000.h5\n",
      "Epoch 13/30\n",
      "34/34 [==============================] - 11s 313ms/step - loss: 0.5334 - categorical_accuracy: 0.8072 - val_loss: 0.4790 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2414_12_25.543099/model-00013-0.53336-0.80719-0.47902-0.80000.h5\n",
      "Epoch 14/30\n",
      "34/34 [==============================] - 11s 316ms/step - loss: 0.3532 - categorical_accuracy: 0.8758 - val_loss: 0.4794 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2414_12_25.543099/model-00014-0.35322-0.87582-0.47937-0.80000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 15/30\n",
      "34/34 [==============================] - 10s 300ms/step - loss: 0.4168 - categorical_accuracy: 0.8431 - val_loss: 0.4767 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2414_12_25.543099/model-00015-0.41682-0.84314-0.47667-0.80000.h5\n",
      "Epoch 16/30\n",
      "34/34 [==============================] - 10s 308ms/step - loss: 0.4406 - categorical_accuracy: 0.8301 - val_loss: 0.4795 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2414_12_25.543099/model-00016-0.44062-0.83007-0.47954-0.80000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 17/30\n",
      "34/34 [==============================] - 10s 302ms/step - loss: 0.4560 - categorical_accuracy: 0.8268 - val_loss: 0.4799 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2414_12_25.543099/model-00017-0.45602-0.82680-0.47995-0.80000.h5\n",
      "Epoch 18/30\n",
      "34/34 [==============================] - 10s 298ms/step - loss: 0.5176 - categorical_accuracy: 0.8170 - val_loss: 0.4832 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2414_12_25.543099/model-00018-0.51762-0.81699-0.48318-0.80000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 19/30\n",
      "34/34 [==============================] - 11s 322ms/step - loss: 0.3972 - categorical_accuracy: 0.8627 - val_loss: 0.4821 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2414_12_25.543099/model-00019-0.39723-0.86275-0.48207-0.80000.h5\n",
      "Epoch 20/30\n",
      "34/34 [==============================] - 10s 301ms/step - loss: 0.4870 - categorical_accuracy: 0.7876 - val_loss: 0.4793 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2414_12_25.543099/model-00020-0.48704-0.78758-0.47930-0.80000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 21/30\n",
      "34/34 [==============================] - 10s 303ms/step - loss: 0.4045 - categorical_accuracy: 0.8562 - val_loss: 0.4821 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-05-2414_12_25.543099/model-00021-0.40446-0.85621-0.48210-0.80000.h5\n",
      "Epoch 22/30\n",
      "34/34 [==============================] - 10s 287ms/step - loss: 0.4468 - categorical_accuracy: 0.8268 - val_loss: 0.4866 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-05-2414_12_25.543099/model-00022-0.44680-0.82680-0.48655-0.80000.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 23/30\n",
      "34/34 [==============================] - 10s 301ms/step - loss: 0.4378 - categorical_accuracy: 0.8464 - val_loss: 0.4789 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-05-2414_12_25.543099/model-00023-0.43777-0.84641-0.47886-0.80000.h5\n",
      "Epoch 24/30\n",
      "34/34 [==============================] - 11s 315ms/step - loss: 0.3974 - categorical_accuracy: 0.8431 - val_loss: 0.4800 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-05-2414_12_25.543099/model-00024-0.39738-0.84314-0.48000-0.80000.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "Epoch 25/30\n",
      "34/34 [==============================] - 10s 308ms/step - loss: 0.3216 - categorical_accuracy: 0.8954 - val_loss: 0.4774 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-05-2414_12_25.543099/model-00025-0.32165-0.89542-0.47738-0.80000.h5\n",
      "Epoch 26/30\n",
      "34/34 [==============================] - 10s 293ms/step - loss: 0.4496 - categorical_accuracy: 0.8627 - val_loss: 0.4759 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-05-2414_12_25.543099/model-00026-0.44963-0.86275-0.47588-0.79000.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 11s 319ms/step - loss: 0.4954 - categorical_accuracy: 0.8039 - val_loss: 0.4765 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-05-2414_12_25.543099/model-00027-0.49536-0.80392-0.47649-0.80000.h5\n",
      "Epoch 28/30\n",
      "34/34 [==============================] - 10s 283ms/step - loss: 0.4020 - categorical_accuracy: 0.8562 - val_loss: 0.4821 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-05-2414_12_25.543099/model-00028-0.40201-0.85621-0.48210-0.80000.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "Epoch 29/30\n",
      "34/34 [==============================] - 11s 310ms/step - loss: 0.4271 - categorical_accuracy: 0.8203 - val_loss: 0.4809 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-05-2414_12_25.543099/model-00029-0.42708-0.82026-0.48091-0.80000.h5\n",
      "Epoch 30/30\n",
      "34/34 [==============================] - 11s 321ms/step - loss: 0.5051 - categorical_accuracy: 0.7908 - val_loss: 0.4755 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-05-2414_12_25.543099/model-00030-0.50507-0.79085-0.47554-0.80000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f135fed1198>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using new number of epochs and fiting the model\n",
    "num_epochs = 30\n",
    "\n",
    "print(\"Total Params:\", model.count_params())\n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 7 -- Framesize = 16, batch_size = 20, epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new batch size\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new check point\n",
    "model_name_7 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_7):\n",
    "    os.mkdir(model_name_7)\n",
    "        \n",
    "filepath = model_name_7 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 864101\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 51s 1s/step - loss: 1.8065 - categorical_accuracy: 0.2615 - val_loss: 1.4462 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2414_33_36.758578/model-00001-1.81465-0.25691-1.44623-0.38000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 6s 186ms/step - loss: 1.5156 - categorical_accuracy: 0.3301 - val_loss: 1.5360 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2414_33_36.758578/model-00002-1.51557-0.33007-1.53600-0.34000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 6s 186ms/step - loss: 1.5991 - categorical_accuracy: 0.3105 - val_loss: 1.4909 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2414_33_36.758578/model-00003-1.59907-0.31046-1.49086-0.33000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.5946 - categorical_accuracy: 0.2582 - val_loss: 1.4523 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2414_33_36.758578/model-00004-1.59463-0.25817-1.45227-0.32000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 7s 206ms/step - loss: 1.4462 - categorical_accuracy: 0.3725 - val_loss: 2.1517 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2414_33_36.758578/model-00005-1.44615-0.37255-2.15168-0.24000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 8s 224ms/step - loss: 1.5015 - categorical_accuracy: 0.3268 - val_loss: 1.3896 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2414_33_36.758578/model-00006-1.50148-0.32680-1.38965-0.35000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 7s 213ms/step - loss: 1.4952 - categorical_accuracy: 0.3595 - val_loss: 1.3429 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2414_33_36.758578/model-00007-1.49521-0.35948-1.34291-0.39000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 8s 249ms/step - loss: 1.4658 - categorical_accuracy: 0.3660 - val_loss: 1.3749 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2414_33_36.758578/model-00008-1.46583-0.36601-1.37488-0.40000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 9s 250ms/step - loss: 1.3926 - categorical_accuracy: 0.3758 - val_loss: 1.3279 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2414_33_36.758578/model-00009-1.39259-0.37582-1.32788-0.42000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 8s 250ms/step - loss: 1.4202 - categorical_accuracy: 0.3987 - val_loss: 1.3210 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2414_33_36.758578/model-00010-1.42020-0.39869-1.32097-0.43000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 8s 247ms/step - loss: 1.3729 - categorical_accuracy: 0.4020 - val_loss: 1.3038 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2414_33_36.758578/model-00011-1.37293-0.40196-1.30376-0.45000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 8s 248ms/step - loss: 1.3806 - categorical_accuracy: 0.3856 - val_loss: 1.3681 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2414_33_36.758578/model-00012-1.38064-0.38562-1.36810-0.38000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 9s 256ms/step - loss: 1.4865 - categorical_accuracy: 0.3824 - val_loss: 1.3328 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2414_33_36.758578/model-00013-1.48655-0.38235-1.33280-0.45000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 9s 252ms/step - loss: 1.2838 - categorical_accuracy: 0.4346 - val_loss: 1.2881 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2414_33_36.758578/model-00014-1.28379-0.43464-1.28808-0.43000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 9s 256ms/step - loss: 1.2867 - categorical_accuracy: 0.4346 - val_loss: 1.2634 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2414_33_36.758578/model-00015-1.28668-0.43464-1.26343-0.48000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 9s 252ms/step - loss: 1.2945 - categorical_accuracy: 0.4379 - val_loss: 1.2611 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2414_33_36.758578/model-00016-1.29450-0.43791-1.26114-0.47000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 9s 251ms/step - loss: 1.3019 - categorical_accuracy: 0.4216 - val_loss: 1.2478 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2414_33_36.758578/model-00017-1.30195-0.42157-1.24780-0.50000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 9s 256ms/step - loss: 1.3480 - categorical_accuracy: 0.4216 - val_loss: 1.2417 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2414_33_36.758578/model-00018-1.34798-0.42157-1.24173-0.47000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 9s 251ms/step - loss: 1.3801 - categorical_accuracy: 0.4216 - val_loss: 1.2679 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2414_33_36.758578/model-00019-1.38005-0.42157-1.26792-0.46000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 9s 250ms/step - loss: 1.2582 - categorical_accuracy: 0.5000 - val_loss: 1.2320 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2414_33_36.758578/model-00020-1.25821-0.50000-1.23198-0.49000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1411cbf7f0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using new epoch number and fiting the model\n",
    "num_epochs = 20\n",
    "\n",
    "print(\"Total Params:\", model.count_params())\n",
    "\n",
    "\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    \n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CNN-RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries for CNN-RNN architecture\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout,LSTM\n",
    "from keras.layers.convolutional import Conv3D,Conv2D, MaxPooling3D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.layers.recurrent import LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the new model by using CNN and RNN layers\n",
    "nb_featuremap = [8,16,32,64]\n",
    "nb_dense = [128,64,5]\n",
    "nb_classes = 5\n",
    "# Input\n",
    "input_shape=(nb_frames,nb_rows,nb_cols,nb_channel)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(nb_classes, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 8 - CNN-RNN - frame size 30, Batch size 10, epoch - 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 128)           401536    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 499,093\n",
      "Trainable params: 498,965\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# using a new batch size and using Adam optimizer \n",
    "batch_size = 10\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimiser =Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "# creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# creating a checkpoint\n",
    "model_name_8 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_8):\n",
    "    os.mkdir(model_name_8)\n",
    "        \n",
    "filepath = model_name_8 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 499093\n",
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n",
      "67/67 [==============================] - 213s 3s/step - loss: 1.2542 - categorical_accuracy: 0.4531 - val_loss: 1.6564 - val_categorical_accuracy: 0.4067\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2414_47_43.025626/model-00001-1.26461-0.44746-1.65639-0.40667.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 1.1781 - categorical_accuracy: 0.5174 - val_loss: 1.3580 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2414_47_43.025626/model-00002-1.17811-0.51741-1.35804-0.47000.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 72s 1s/step - loss: 1.1828 - categorical_accuracy: 0.5257 - val_loss: 1.2839 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2414_47_43.025626/model-00003-1.18281-0.52570-1.28393-0.51667.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 1.1411 - categorical_accuracy: 0.5456 - val_loss: 2.0395 - val_categorical_accuracy: 0.3867\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2414_47_43.025626/model-00004-1.14105-0.54561-2.03946-0.38667.h5\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 0.9310 - categorical_accuracy: 0.6584 - val_loss: 1.8100 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2414_47_43.025626/model-00005-0.93096-0.65837-1.81004-0.42000.h5\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.8705 - categorical_accuracy: 0.6683 - val_loss: 1.5075 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2414_47_43.025626/model-00006-0.87050-0.66833-1.50750-0.49000.h5\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 72s 1s/step - loss: 0.9591 - categorical_accuracy: 0.6368 - val_loss: 1.0122 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2414_47_43.025626/model-00007-0.95908-0.63682-1.01219-0.64000.h5\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.7390 - categorical_accuracy: 0.7280 - val_loss: 0.8668 - val_categorical_accuracy: 0.6967\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2414_47_43.025626/model-00008-0.73897-0.72803-0.86681-0.69667.h5\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.5224 - categorical_accuracy: 0.8043 - val_loss: 1.3937 - val_categorical_accuracy: 0.4867\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2414_47_43.025626/model-00009-0.52241-0.80431-1.39371-0.48667.h5\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.6112 - categorical_accuracy: 0.7728 - val_loss: 1.2174 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2414_47_43.025626/model-00010-0.61124-0.77280-1.21741-0.57000.h5\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.6081 - categorical_accuracy: 0.7761 - val_loss: 0.9421 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2414_47_43.025626/model-00011-0.60810-0.77612-0.94214-0.65000.h5\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 0.4347 - categorical_accuracy: 0.8441 - val_loss: 1.0829 - val_categorical_accuracy: 0.6267\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2414_47_43.025626/model-00012-0.43469-0.84411-1.08290-0.62667.h5\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 0.5061 - categorical_accuracy: 0.8060 - val_loss: 0.8822 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2414_47_43.025626/model-00013-0.50607-0.80597-0.88217-0.67000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.4268 - categorical_accuracy: 0.8507 - val_loss: 0.8001 - val_categorical_accuracy: 0.7067\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2414_47_43.025626/model-00014-0.42676-0.85075-0.80007-0.70667.h5\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.3651 - categorical_accuracy: 0.8823 - val_loss: 0.7543 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2414_47_43.025626/model-00015-0.36508-0.88226-0.75433-0.73333.h5\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.2957 - categorical_accuracy: 0.9055 - val_loss: 0.7240 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2414_47_43.025626/model-00016-0.29571-0.90547-0.72397-0.76000.h5\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.3158 - categorical_accuracy: 0.8889 - val_loss: 0.7110 - val_categorical_accuracy: 0.7567\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2414_47_43.025626/model-00017-0.31581-0.88889-0.71098-0.75667.h5\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 76s 1s/step - loss: 0.2383 - categorical_accuracy: 0.9370 - val_loss: 0.7178 - val_categorical_accuracy: 0.7533\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2414_47_43.025626/model-00018-0.23830-0.93698-0.71780-0.75333.h5\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.2702 - categorical_accuracy: 0.9171 - val_loss: 0.7038 - val_categorical_accuracy: 0.7533\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2414_47_43.025626/model-00019-0.27025-0.91708-0.70379-0.75333.h5\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.2553 - categorical_accuracy: 0.9221 - val_loss: 0.6998 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2414_47_43.025626/model-00020-0.25527-0.92206-0.69985-0.75000.h5\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.3126 - categorical_accuracy: 0.8839 - val_loss: 0.6986 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-05-2414_47_43.025626/model-00021-0.31256-0.88391-0.69860-0.76000.h5\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.2694 - categorical_accuracy: 0.9221 - val_loss: 0.6941 - val_categorical_accuracy: 0.7567\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-05-2414_47_43.025626/model-00022-0.26936-0.92206-0.69407-0.75667.h5\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.2837 - categorical_accuracy: 0.9055 - val_loss: 0.6957 - val_categorical_accuracy: 0.7533\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-05-2414_47_43.025626/model-00023-0.28373-0.90547-0.69566-0.75333.h5\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 72s 1s/step - loss: 0.2509 - categorical_accuracy: 0.9237 - val_loss: 0.7041 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-05-2414_47_43.025626/model-00024-0.25088-0.92371-0.70409-0.76000.h5\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.2455 - categorical_accuracy: 0.9204 - val_loss: 0.6899 - val_categorical_accuracy: 0.7433\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-05-2414_47_43.025626/model-00025-0.24553-0.92040-0.68988-0.74333.h5\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 72s 1s/step - loss: 0.2580 - categorical_accuracy: 0.9254 - val_loss: 0.7105 - val_categorical_accuracy: 0.7533\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-05-2414_47_43.025626/model-00026-0.25804-0.92537-0.71047-0.75333.h5\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 0.2560 - categorical_accuracy: 0.9121 - val_loss: 0.7038 - val_categorical_accuracy: 0.7633\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-05-2414_47_43.025626/model-00027-0.25599-0.91211-0.70381-0.76333.h5\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.2426 - categorical_accuracy: 0.9171 - val_loss: 0.6899 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-05-2414_47_43.025626/model-00028-0.24256-0.91708-0.68988-0.76000.h5\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.2431 - categorical_accuracy: 0.9353 - val_loss: 0.6960 - val_categorical_accuracy: 0.7533\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-05-2414_47_43.025626/model-00029-0.24308-0.93532-0.69599-0.75333.h5\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 72s 1s/step - loss: 0.2362 - categorical_accuracy: 0.9320 - val_loss: 0.6890 - val_categorical_accuracy: 0.7633\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-05-2414_47_43.025626/model-00030-0.23624-0.93201-0.68901-0.76333.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82a1bc6e80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fiting the model\n",
    "print(\"Total Params:\", model.count_params())\n",
    "num_epochs = 30\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,\n",
    "                    verbose=1,callbacks=callbacks_list, validation_data=val_generator,validation_steps=validation_steps, \n",
    "                    class_weight=None,\n",
    "                    workers=1, initial_epoch=0,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 9 - CNN-RNN - frame size 30, Batch size 20, epoch - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 128)           401536    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 499,093\n",
      "Trainable params: 498,965\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimiser =Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "# creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# creating the checkpoint and filepath\n",
    "model_name_9 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_9):\n",
    "    os.mkdir(model_name_9)\n",
    "        \n",
    "filepath = model_name_9 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 499093\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 304s 9s/step - loss: 0.2081 - categorical_accuracy: 0.9313 - val_loss: 1.0802 - val_categorical_accuracy: 0.7067\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2414_47_43.025626/model-00001-0.21232-0.92961-1.08020-0.70667.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.1691 - categorical_accuracy: 0.9379 - val_loss: 1.7116 - val_categorical_accuracy: 0.5967\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2414_47_43.025626/model-00002-0.16910-0.93791-1.71160-0.59667.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.3862 - categorical_accuracy: 0.8595 - val_loss: 2.1339 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2414_47_43.025626/model-00003-0.38624-0.85948-2.13387-0.44000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.3901 - categorical_accuracy: 0.8366 - val_loss: 0.9367 - val_categorical_accuracy: 0.7267\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2414_47_43.025626/model-00004-0.39006-0.83660-0.93670-0.72667.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.4005 - categorical_accuracy: 0.8529 - val_loss: 1.1701 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2414_47_43.025626/model-00005-0.40048-0.85294-1.17012-0.65000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.3350 - categorical_accuracy: 0.8660 - val_loss: 0.7664 - val_categorical_accuracy: 0.7467\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2414_47_43.025626/model-00006-0.33502-0.86601-0.76638-0.74667.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.2841 - categorical_accuracy: 0.9052 - val_loss: 0.8356 - val_categorical_accuracy: 0.6933\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2414_47_43.025626/model-00007-0.28415-0.90523-0.83556-0.69333.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.3953 - categorical_accuracy: 0.8497 - val_loss: 2.1604 - val_categorical_accuracy: 0.4633\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2414_47_43.025626/model-00008-0.39530-0.84967-2.16039-0.46333.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.1854 - categorical_accuracy: 0.9346 - val_loss: 1.1222 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2414_47_43.025626/model-00009-0.18544-0.93464-1.12222-0.65667.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.1079 - categorical_accuracy: 0.9804 - val_loss: 1.0571 - val_categorical_accuracy: 0.7267\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2414_47_43.025626/model-00010-0.10788-0.98039-1.05708-0.72667.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.1737 - categorical_accuracy: 0.9412 - val_loss: 1.0971 - val_categorical_accuracy: 0.6733\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2414_47_43.025626/model-00011-0.17371-0.94118-1.09709-0.67333.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.3178 - categorical_accuracy: 0.8660 - val_loss: 0.9666 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2414_47_43.025626/model-00012-0.31775-0.86601-0.96661-0.70000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.2861 - categorical_accuracy: 0.8987 - val_loss: 0.8940 - val_categorical_accuracy: 0.7233\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2414_47_43.025626/model-00013-0.28614-0.89869-0.89404-0.72333.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.1875 - categorical_accuracy: 0.9379 - val_loss: 0.8535 - val_categorical_accuracy: 0.7367\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2414_47_43.025626/model-00014-0.18746-0.93791-0.85346-0.73667.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.1187 - categorical_accuracy: 0.9706 - val_loss: 0.8246 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2414_47_43.025626/model-00015-0.11869-0.97059-0.82465-0.74000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.1439 - categorical_accuracy: 0.9379 - val_loss: 0.8125 - val_categorical_accuracy: 0.7433\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2414_47_43.025626/model-00016-0.14389-0.93791-0.81250-0.74333.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.1010 - categorical_accuracy: 0.9739 - val_loss: 0.8008 - val_categorical_accuracy: 0.7467\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2414_47_43.025626/model-00017-0.10102-0.97386-0.80075-0.74667.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.1533 - categorical_accuracy: 0.9444 - val_loss: 0.7967 - val_categorical_accuracy: 0.7533\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2414_47_43.025626/model-00018-0.15333-0.94444-0.79671-0.75333.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.0776 - categorical_accuracy: 0.9771 - val_loss: 0.7824 - val_categorical_accuracy: 0.7567\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2414_47_43.025626/model-00019-0.07758-0.97712-0.78237-0.75667.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.0903 - categorical_accuracy: 0.9673 - val_loss: 0.7888 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2414_47_43.025626/model-00020-0.09027-0.96732-0.78878-0.76000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82a1bc6d30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the number of paramerets in the model\n",
    "print(\"Total Params:\", model.count_params())\n",
    "num_epochs = 20\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,\n",
    "                    verbose=1,callbacks=callbacks_list, validation_data=val_generator,validation_steps=validation_steps, \n",
    "                    class_weight=None,\n",
    "                    workers=1, initial_epoch=0,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 10 - CNN-RNN - frame size 20, Batch size 10, epoch - 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "from keras.optimizers import Adam\n",
    "# using Adam optimiser\n",
    "optimiser =Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "# creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a checkpoint and a file path\n",
    "model_name_10 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_10):\n",
    "    os.mkdir(model_name_10)\n",
    "        \n",
    "filepath = model_name_10 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 499093\n",
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n",
      "67/67 [==============================] - 141s 2s/step - loss: 1.3600 - categorical_accuracy: 0.3964 - val_loss: 1.4789 - val_categorical_accuracy: 0.4433\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2218_33_33.160458/model-00001-1.35805-0.39819-1.47892-0.44333.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 48s 710ms/step - loss: 1.2267 - categorical_accuracy: 0.5025 - val_loss: 1.5807 - val_categorical_accuracy: 0.3767\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2218_33_33.160458/model-00002-1.22674-0.50249-1.58069-0.37667.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 49s 726ms/step - loss: 1.4445 - categorical_accuracy: 0.4129 - val_loss: 1.4712 - val_categorical_accuracy: 0.4333\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2218_33_33.160458/model-00003-1.44455-0.41294-1.47116-0.43333.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 47s 708ms/step - loss: 1.3043 - categorical_accuracy: 0.4577 - val_loss: 1.4353 - val_categorical_accuracy: 0.3533\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2218_33_33.160458/model-00004-1.30430-0.45771-1.43529-0.35333.h5\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 47s 708ms/step - loss: 1.1648 - categorical_accuracy: 0.5589 - val_loss: 2.0310 - val_categorical_accuracy: 0.3333\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2218_33_33.160458/model-00005-1.16481-0.55887-2.03102-0.33333.h5\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 48s 713ms/step - loss: 1.0890 - categorical_accuracy: 0.5804 - val_loss: 2.8303 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2218_33_33.160458/model-00006-1.08904-0.58043-2.83028-0.25000.h5\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 49s 729ms/step - loss: 1.0551 - categorical_accuracy: 0.5887 - val_loss: 1.3079 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2218_33_33.160458/model-00007-1.05512-0.58872-1.30788-0.50000.h5\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 48s 710ms/step - loss: 0.9917 - categorical_accuracy: 0.6285 - val_loss: 1.4826 - val_categorical_accuracy: 0.4733\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2218_33_33.160458/model-00008-0.99173-0.62852-1.48258-0.47333.h5\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 50s 743ms/step - loss: 0.8060 - categorical_accuracy: 0.6915 - val_loss: 1.8153 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2218_33_33.160458/model-00009-0.80597-0.69154-1.81525-0.36667.h5\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 48s 709ms/step - loss: 0.8047 - categorical_accuracy: 0.6932 - val_loss: 1.4608 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2218_33_33.160458/model-00010-0.80469-0.69320-1.46078-0.50000.h5\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 47s 709ms/step - loss: 0.8715 - categorical_accuracy: 0.6833 - val_loss: 1.6033 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2218_33_33.160458/model-00011-0.87146-0.68325-1.60333-0.45000.h5\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 48s 717ms/step - loss: 0.5002 - categorical_accuracy: 0.8226 - val_loss: 1.3808 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2218_33_33.160458/model-00012-0.50015-0.82255-1.38080-0.57000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 48s 723ms/step - loss: 0.6069 - categorical_accuracy: 0.7877 - val_loss: 1.2575 - val_categorical_accuracy: 0.6033\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2218_33_33.160458/model-00013-0.60693-0.78773-1.25753-0.60333.h5\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 49s 734ms/step - loss: 0.5314 - categorical_accuracy: 0.7910 - val_loss: 1.1615 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2218_33_33.160458/model-00014-0.53140-0.79104-1.16149-0.64000.h5\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 48s 710ms/step - loss: 0.4722 - categorical_accuracy: 0.8408 - val_loss: 1.1252 - val_categorical_accuracy: 0.6467\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2218_33_33.160458/model-00015-0.47221-0.84080-1.12524-0.64667.h5\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 49s 725ms/step - loss: 0.4960 - categorical_accuracy: 0.8126 - val_loss: 1.0606 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2218_33_33.160458/model-00016-0.49597-0.81260-1.06064-0.66000.h5\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 48s 716ms/step - loss: 0.4063 - categorical_accuracy: 0.8624 - val_loss: 1.0694 - val_categorical_accuracy: 0.6367\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2218_33_33.160458/model-00017-0.40632-0.86235-1.06944-0.63667.h5\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 48s 722ms/step - loss: 0.4192 - categorical_accuracy: 0.8458 - val_loss: 1.0334 - val_categorical_accuracy: 0.6433\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2218_33_33.160458/model-00018-0.41919-0.84577-1.03339-0.64333.h5\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 47s 698ms/step - loss: 0.4091 - categorical_accuracy: 0.8574 - val_loss: 1.0273 - val_categorical_accuracy: 0.6533\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2218_33_33.160458/model-00019-0.40911-0.85738-1.02733-0.65333.h5\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 48s 716ms/step - loss: 0.3676 - categorical_accuracy: 0.8856 - val_loss: 1.0276 - val_categorical_accuracy: 0.6533\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2218_33_33.160458/model-00020-0.36763-0.88557-1.02756-0.65333.h5\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 50s 741ms/step - loss: 0.3810 - categorical_accuracy: 0.8690 - val_loss: 1.0072 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-05-2218_33_33.160458/model-00021-0.38098-0.86899-1.00723-0.65667.h5\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 48s 712ms/step - loss: 0.4051 - categorical_accuracy: 0.8839 - val_loss: 1.0092 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-05-2218_33_33.160458/model-00022-0.40508-0.88391-1.00924-0.65667.h5\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 47s 704ms/step - loss: 0.4030 - categorical_accuracy: 0.8541 - val_loss: 1.0085 - val_categorical_accuracy: 0.6533\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-05-2218_33_33.160458/model-00023-0.40300-0.85406-1.00846-0.65333.h5\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 48s 714ms/step - loss: 0.3483 - categorical_accuracy: 0.8922 - val_loss: 0.9952 - val_categorical_accuracy: 0.6633\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-05-2218_33_33.160458/model-00024-0.34827-0.89221-0.99525-0.66333.h5\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 47s 708ms/step - loss: 0.3518 - categorical_accuracy: 0.8889 - val_loss: 0.9874 - val_categorical_accuracy: 0.6433\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-05-2218_33_33.160458/model-00025-0.35175-0.88889-0.98741-0.64333.h5\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 48s 710ms/step - loss: 0.3655 - categorical_accuracy: 0.8856 - val_loss: 0.9928 - val_categorical_accuracy: 0.6533\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-05-2218_33_33.160458/model-00026-0.36549-0.88557-0.99280-0.65333.h5\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 48s 721ms/step - loss: 0.3773 - categorical_accuracy: 0.8657 - val_loss: 0.9820 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-05-2218_33_33.160458/model-00027-0.37729-0.86567-0.98195-0.65667.h5\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 48s 717ms/step - loss: 0.3913 - categorical_accuracy: 0.8673 - val_loss: 0.9967 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-05-2218_33_33.160458/model-00028-0.39126-0.86733-0.99667-0.65667.h5\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 47s 696ms/step - loss: 0.2929 - categorical_accuracy: 0.9138 - val_loss: 0.9959 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-05-2218_33_33.160458/model-00029-0.29288-0.91376-0.99591-0.65667.h5\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 49s 726ms/step - loss: 0.3587 - categorical_accuracy: 0.8823 - val_loss: 0.9857 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-05-2218_33_33.160458/model-00030-0.35874-0.88226-0.98570-0.65667.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f29e3eb7940>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the number of parameters\n",
    "print(\"Total Params:\", model.count_params())\n",
    "num_epochs = 20\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,\n",
    "                    verbose=1,callbacks=callbacks_list, validation_data=val_generator,validation_steps=validation_steps, \n",
    "                    class_weight=None,\n",
    "                    workers=1, initial_epoch=0,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 11 - CNN-RNN - frame size 20, Batch size 20, epoch - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 20, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 20, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 20, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 20, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 20, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 20, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 20, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20, 128)           401536    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 499,093\n",
      "Trainable params: 498,965\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimiser =Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "# creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# creating a check point, and a file path\n",
    "model_name_11 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_11):\n",
    "    os.mkdir(model_name_11)\n",
    "        \n",
    "filepath = model_name_11 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 499093\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.3295 - categorical_accuracy: 0.8867 - val_loss: 1.4224 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2218_33_33.160458/model-00001-0.33446-0.88386-1.42238-0.55000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 29s 848ms/step - loss: 0.4508 - categorical_accuracy: 0.8529 - val_loss: 1.7612 - val_categorical_accuracy: 0.5467\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2218_33_33.160458/model-00002-0.45085-0.85294-1.76117-0.54667.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 29s 860ms/step - loss: 0.6299 - categorical_accuracy: 0.7908 - val_loss: 2.7543 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2218_33_33.160458/model-00003-0.62985-0.79085-2.75427-0.35000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 29s 851ms/step - loss: 0.4949 - categorical_accuracy: 0.8105 - val_loss: 1.4586 - val_categorical_accuracy: 0.5267\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2218_33_33.160458/model-00004-0.49490-0.81046-1.45859-0.52667.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 30s 886ms/step - loss: 0.5115 - categorical_accuracy: 0.8170 - val_loss: 1.4357 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2218_33_33.160458/model-00005-0.51149-0.81699-1.43568-0.56667.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 29s 851ms/step - loss: 0.5370 - categorical_accuracy: 0.8039 - val_loss: 1.3476 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2218_33_33.160458/model-00006-0.53699-0.80392-1.34755-0.61667.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 29s 851ms/step - loss: 0.5028 - categorical_accuracy: 0.8235 - val_loss: 1.1266 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2218_33_33.160458/model-00007-0.50275-0.82353-1.12664-0.60000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 29s 868ms/step - loss: 0.4166 - categorical_accuracy: 0.8464 - val_loss: 1.5127 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2218_33_33.160458/model-00008-0.41661-0.84641-1.51275-0.52000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 29s 861ms/step - loss: 0.2928 - categorical_accuracy: 0.8954 - val_loss: 1.7798 - val_categorical_accuracy: 0.5267\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2218_33_33.160458/model-00009-0.29279-0.89542-1.77978-0.52667.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 29s 858ms/step - loss: 0.3213 - categorical_accuracy: 0.8954 - val_loss: 1.2349 - val_categorical_accuracy: 0.6433\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2218_33_33.160458/model-00010-0.32125-0.89542-1.23487-0.64333.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 29s 856ms/step - loss: 0.3893 - categorical_accuracy: 0.8595 - val_loss: 1.3401 - val_categorical_accuracy: 0.6033\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2218_33_33.160458/model-00011-0.38934-0.85948-1.34008-0.60333.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 29s 849ms/step - loss: 0.3755 - categorical_accuracy: 0.8627 - val_loss: 1.8062 - val_categorical_accuracy: 0.5433\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2218_33_33.160458/model-00012-0.37546-0.86275-1.80624-0.54333.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 29s 855ms/step - loss: 0.4287 - categorical_accuracy: 0.8497 - val_loss: 1.4828 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2218_33_33.160458/model-00013-0.42870-0.84967-1.48279-0.61667.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 29s 858ms/step - loss: 0.3959 - categorical_accuracy: 0.8595 - val_loss: 1.4091 - val_categorical_accuracy: 0.6533\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2218_33_33.160458/model-00014-0.39589-0.85948-1.40911-0.65333.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 29s 850ms/step - loss: 0.2750 - categorical_accuracy: 0.8954 - val_loss: 1.3508 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2218_33_33.160458/model-00015-0.27500-0.89542-1.35082-0.66667.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 29s 852ms/step - loss: 0.2466 - categorical_accuracy: 0.9118 - val_loss: 1.3216 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2218_33_33.160458/model-00016-0.24662-0.91176-1.32159-0.66667.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 29s 845ms/step - loss: 0.2597 - categorical_accuracy: 0.9085 - val_loss: 1.3075 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2218_33_33.160458/model-00017-0.25971-0.90850-1.30749-0.67000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 29s 856ms/step - loss: 0.2233 - categorical_accuracy: 0.9216 - val_loss: 1.3023 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2218_33_33.160458/model-00018-0.22330-0.92157-1.30225-0.66667.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 28s 836ms/step - loss: 0.1717 - categorical_accuracy: 0.9575 - val_loss: 1.2812 - val_categorical_accuracy: 0.6733\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2218_33_33.160458/model-00019-0.17168-0.95752-1.28117-0.67333.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 29s 846ms/step - loss: 0.2579 - categorical_accuracy: 0.9085 - val_loss: 1.2788 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2218_33_33.160458/model-00020-0.25786-0.90850-1.27884-0.68000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f29f9f3a2e8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the number of parameters\n",
    "print(\"Total Params:\", model.count_params())\n",
    "num_epochs = 20\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,\n",
    "                    verbose=1,callbacks=callbacks_list, validation_data=val_generator,validation_steps=validation_steps, \n",
    "                    class_weight=None,\n",
    "                    workers=1, initial_epoch=0,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 12 - CNN-RNN - LSTM- frame size 30, Batch size 10, epoch - 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new CNN-RNN model by adding some new extra layers to existing model\n",
    "nb_featuremap = [8,16,32,64]\n",
    "nb_dense = [128,64,5]\n",
    "nb_classes = 5\n",
    "# Input\n",
    "input_shape=(nb_frames,nb_rows,nb_cols,nb_channel)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "## model.add(GRU(128, return_sequences=False))\n",
    "## model.add(Dense(nb_classes, activation='softmax')) \n",
    "\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.25))\n",
    "        \n",
    "model.add(Dense(nb_dense[1],activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "        \n",
    "model.add(Dense(nb_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_10 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30, 128)           401536    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 531,733\n",
      "Trainable params: 531,605\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# using Adam optimiser and a batch size of 10\n",
    "batch_size = 10\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimiser =Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "# creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# creating a checkpoint\n",
    "model_name_12 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_12):\n",
    "    os.mkdir(model_name_12)\n",
    "        \n",
    "filepath = model_name_12 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 531733\n",
      "Source path =  ./Project_data/val ; batch size = 10\n",
      "Source path =  ./Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n",
      "67/67 [==============================] - 212s 3s/step - loss: 1.3688 - categorical_accuracy: 0.3761 - val_loss: 1.2730 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2414_47_43.025626/model-00001-1.37506-0.37305-1.27301-0.48333.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 1.3768 - categorical_accuracy: 0.4229 - val_loss: 1.3526 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2414_47_43.025626/model-00002-1.37678-0.42289-1.35259-0.45000.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 1.3170 - categorical_accuracy: 0.4660 - val_loss: 1.3638 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2414_47_43.025626/model-00003-1.31701-0.46600-1.36382-0.40000.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 76s 1s/step - loss: 1.2284 - categorical_accuracy: 0.5191 - val_loss: 2.5921 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2414_47_43.025626/model-00004-1.22835-0.51907-2.59211-0.16000.h5\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 1.2165 - categorical_accuracy: 0.5008 - val_loss: 1.1660 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2414_47_43.025626/model-00005-1.21654-0.50083-1.16602-0.58333.h5\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 1.2232 - categorical_accuracy: 0.5357 - val_loss: 1.4680 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2414_47_43.025626/model-00006-1.22323-0.53566-1.46797-0.40000.h5\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 72s 1s/step - loss: 1.1919 - categorical_accuracy: 0.5158 - val_loss: 1.6439 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2414_47_43.025626/model-00007-1.19195-0.51575-1.64394-0.30000.h5\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 1.1265 - categorical_accuracy: 0.5705 - val_loss: 2.3753 - val_categorical_accuracy: 0.2667\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2414_47_43.025626/model-00008-1.12653-0.57048-2.37528-0.26667.h5\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 1.1887 - categorical_accuracy: 0.5605 - val_loss: 1.5742 - val_categorical_accuracy: 0.4433\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2414_47_43.025626/model-00009-1.18874-0.56053-1.57420-0.44333.h5\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 1.0499 - categorical_accuracy: 0.6269 - val_loss: 1.4598 - val_categorical_accuracy: 0.4367\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2414_47_43.025626/model-00010-1.04994-0.62687-1.45983-0.43667.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.9726 - categorical_accuracy: 0.6584 - val_loss: 1.2152 - val_categorical_accuracy: 0.5533\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2414_47_43.025626/model-00011-0.97260-0.65837-1.21524-0.55333.h5\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.9572 - categorical_accuracy: 0.6335 - val_loss: 1.0983 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2414_47_43.025626/model-00012-0.95721-0.63350-1.09830-0.63000.h5\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.9115 - categorical_accuracy: 0.6683 - val_loss: 1.0353 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2414_47_43.025626/model-00013-0.91153-0.66833-1.03529-0.65000.h5\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.8954 - categorical_accuracy: 0.6949 - val_loss: 1.0304 - val_categorical_accuracy: 0.6467\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2414_47_43.025626/model-00014-0.89537-0.69486-1.03040-0.64667.h5\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.9844 - categorical_accuracy: 0.6352 - val_loss: 1.0156 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2414_47_43.025626/model-00015-0.98443-0.63516-1.01559-0.63000.h5\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 72s 1s/step - loss: 0.8236 - categorical_accuracy: 0.7131 - val_loss: 1.0120 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2414_47_43.025626/model-00016-0.82362-0.71310-1.01199-0.64000.h5\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 72s 1s/step - loss: 0.9262 - categorical_accuracy: 0.6534 - val_loss: 1.0057 - val_categorical_accuracy: 0.6433\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2414_47_43.025626/model-00017-0.92621-0.65340-1.00567-0.64333.h5\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.9217 - categorical_accuracy: 0.6551 - val_loss: 0.9957 - val_categorical_accuracy: 0.6533\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2414_47_43.025626/model-00018-0.92167-0.65506-0.99571-0.65333.h5\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.8710 - categorical_accuracy: 0.6849 - val_loss: 0.9987 - val_categorical_accuracy: 0.6467\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2414_47_43.025626/model-00019-0.87102-0.68491-0.99867-0.64667.h5\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.9663 - categorical_accuracy: 0.6501 - val_loss: 0.9895 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2414_47_43.025626/model-00020-0.96632-0.65008-0.98946-0.65667.h5\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.8330 - categorical_accuracy: 0.7048 - val_loss: 0.9825 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-05-2414_47_43.025626/model-00021-0.83298-0.70481-0.98255-0.66000.h5\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.8415 - categorical_accuracy: 0.7164 - val_loss: 0.9854 - val_categorical_accuracy: 0.6733\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-05-2414_47_43.025626/model-00022-0.84149-0.71642-0.98540-0.67333.h5\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 0.9153 - categorical_accuracy: 0.6451 - val_loss: 0.9843 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-05-2414_47_43.025626/model-00023-0.91532-0.64511-0.98431-0.65667.h5\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.9011 - categorical_accuracy: 0.6517 - val_loss: 0.9873 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-05-2414_47_43.025626/model-00024-0.90109-0.65174-0.98735-0.65000.h5\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 74s 1s/step - loss: 0.9278 - categorical_accuracy: 0.6667 - val_loss: 0.9876 - val_categorical_accuracy: 0.6467\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-05-2414_47_43.025626/model-00025-0.92779-0.66667-0.98760-0.64667.h5\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.8452 - categorical_accuracy: 0.6982 - val_loss: 0.9697 - val_categorical_accuracy: 0.6633\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-05-2414_47_43.025626/model-00026-0.84519-0.69818-0.96974-0.66333.h5\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 73s 1s/step - loss: 0.9289 - categorical_accuracy: 0.6866 - val_loss: 0.9665 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-05-2414_47_43.025626/model-00027-0.92891-0.68657-0.96648-0.68000.h5\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 0.7463 - categorical_accuracy: 0.7330 - val_loss: 0.9675 - val_categorical_accuracy: 0.6733\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-05-2414_47_43.025626/model-00028-0.74633-0.73300-0.96745-0.67333.h5\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 75s 1s/step - loss: 0.8424 - categorical_accuracy: 0.6949 - val_loss: 0.9558 - val_categorical_accuracy: 0.6733\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-05-2414_47_43.025626/model-00029-0.84243-0.69486-0.95581-0.67333.h5\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 74s 1s/step - loss: 0.8412 - categorical_accuracy: 0.7032 - val_loss: 0.9657 - val_categorical_accuracy: 0.6767\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-05-2414_47_43.025626/model-00030-0.84122-0.70315-0.96567-0.67667.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8252bc9048>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the total number of parameters and fitting the model\n",
    "print(\"Total Params:\", model.count_params())\n",
    "num_epochs = 30\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,\n",
    "                    verbose=1,callbacks=callbacks_list, validation_data=val_generator,validation_steps=validation_steps, \n",
    "                    class_weight=None,\n",
    "                    workers=1, initial_epoch=0,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 13 - CNN-RNN - LSTM- frame size 30, Batch size 20, epoch - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 128)           401536    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 499,093\n",
      "Trainable params: 498,965\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# using Adam Optizer and using batch size as 20\n",
    "batch_size = 20\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimiser =Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "# creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# creating the checkpoint\n",
    "model_name_13 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_13):\n",
    "    os.mkdir(model_name_13)\n",
    "        \n",
    "filepath = model_name_13 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 499093\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 295s 9s/step - loss: 1.0589 - categorical_accuracy: 0.5681 - val_loss: 1.0425 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2417_27_20.041494/model-00001-1.04501-0.57667-1.04247-0.59000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.9478 - categorical_accuracy: 0.6340 - val_loss: 1.8359 - val_categorical_accuracy: 0.4333\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2417_27_20.041494/model-00002-0.94781-0.63399-1.83591-0.43333.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 50s 1s/step - loss: 1.0710 - categorical_accuracy: 0.6209 - val_loss: 1.8938 - val_categorical_accuracy: 0.4433\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2417_27_20.041494/model-00003-1.07099-0.62092-1.89380-0.44333.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 50s 1s/step - loss: 1.0896 - categorical_accuracy: 0.6111 - val_loss: 2.9160 - val_categorical_accuracy: 0.2933\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2417_27_20.041494/model-00004-1.08956-0.61111-2.91596-0.29333.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 54s 2s/step - loss: 1.2112 - categorical_accuracy: 0.5196 - val_loss: 1.3009 - val_categorical_accuracy: 0.5067\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2417_27_20.041494/model-00005-1.21117-0.51961-1.30088-0.50667.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 50s 1s/step - loss: 1.1657 - categorical_accuracy: 0.5654 - val_loss: 1.3102 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2417_27_20.041494/model-00006-1.16570-0.56536-1.31017-0.49000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 50s 1s/step - loss: 1.2196 - categorical_accuracy: 0.5131 - val_loss: 1.2255 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2417_27_20.041494/model-00007-1.21955-0.51307-1.22552-0.51667.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.9786 - categorical_accuracy: 0.6209 - val_loss: 1.2136 - val_categorical_accuracy: 0.5433\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2417_27_20.041494/model-00008-0.97861-0.62092-1.21356-0.54333.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 51s 2s/step - loss: 0.8466 - categorical_accuracy: 0.6928 - val_loss: 1.1909 - val_categorical_accuracy: 0.5433\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2417_27_20.041494/model-00009-0.84657-0.69281-1.19093-0.54333.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.7381 - categorical_accuracy: 0.7418 - val_loss: 1.1685 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2417_27_20.041494/model-00010-0.73813-0.74183-1.16848-0.54000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.9504 - categorical_accuracy: 0.6438 - val_loss: 1.1408 - val_categorical_accuracy: 0.5567\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2417_27_20.041494/model-00011-0.95037-0.64379-1.14077-0.55667.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.9034 - categorical_accuracy: 0.6797 - val_loss: 1.1093 - val_categorical_accuracy: 0.5733\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2417_27_20.041494/model-00012-0.90341-0.67974-1.10927-0.57333.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.8638 - categorical_accuracy: 0.6895 - val_loss: 1.0869 - val_categorical_accuracy: 0.5733\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2417_27_20.041494/model-00013-0.86381-0.68954-1.08693-0.57333.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 53s 2s/step - loss: 0.8614 - categorical_accuracy: 0.6928 - val_loss: 1.0806 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2417_27_20.041494/model-00014-0.86140-0.69281-1.08060-0.57000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 48s 1s/step - loss: 0.8650 - categorical_accuracy: 0.6699 - val_loss: 1.0631 - val_categorical_accuracy: 0.5767\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2417_27_20.041494/model-00015-0.86498-0.66993-1.06314-0.57667.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.8247 - categorical_accuracy: 0.7059 - val_loss: 1.0533 - val_categorical_accuracy: 0.5933\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2417_27_20.041494/model-00016-0.82474-0.70588-1.05330-0.59333.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.8469 - categorical_accuracy: 0.6536 - val_loss: 1.0437 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2417_27_20.041494/model-00017-0.84689-0.65359-1.04366-0.59000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.8631 - categorical_accuracy: 0.6961 - val_loss: 1.0455 - val_categorical_accuracy: 0.5867\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2417_27_20.041494/model-00018-0.86306-0.69608-1.04547-0.58667.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 51s 2s/step - loss: 0.8996 - categorical_accuracy: 0.6438 - val_loss: 1.0452 - val_categorical_accuracy: 0.5933\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2417_27_20.041494/model-00019-0.89958-0.64379-1.04519-0.59333.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 52s 2s/step - loss: 0.7868 - categorical_accuracy: 0.7418 - val_loss: 1.0487 - val_categorical_accuracy: 0.5933\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2417_27_20.041494/model-00020-0.78676-0.74183-1.04873-0.59333.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2608b9f320>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the number of parameters and fiting the model\n",
    "print(\"Total Params:\", model.count_params())\n",
    "num_epochs = 20\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,\n",
    "                    verbose=1,callbacks=callbacks_list, validation_data=val_generator,validation_steps=validation_steps, \n",
    "                    class_weight=None,\n",
    "                    workers=1, initial_epoch=0,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 14 - CNN-RNN - LSTM- frame size 30, Batch size 20, epoch - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_10 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30, 128)           401536    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 30, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 531,733\n",
      "Trainable params: 531,605\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# using Adam optimizer\n",
    "optimiser =Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "# creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# creating the checkpoint\n",
    "model_name_14 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_14):\n",
    "    os.mkdir(model_name_14)\n",
    "        \n",
    "filepath = model_name_14 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 531733\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 268s 8s/step - loss: 1.3976 - categorical_accuracy: 0.3454 - val_loss: 1.8120 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2506_37_23.930997/model-00001-1.40517-0.34289-1.81203-0.32000.h5\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 50s 1s/step - loss: 1.3576 - categorical_accuracy: 0.4248 - val_loss: 2.0048 - val_categorical_accuracy: 0.3067\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2506_37_23.930997/model-00002-1.35759-0.42484-2.00481-0.30667.h5\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.5315 - categorical_accuracy: 0.3301 - val_loss: 1.6098 - val_categorical_accuracy: 0.2467\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2506_37_23.930997/model-00003-1.53146-0.33007-1.60976-0.24667.h5\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 47s 1s/step - loss: 1.3681 - categorical_accuracy: 0.4248 - val_loss: 2.0055 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2506_37_23.930997/model-00004-1.36810-0.42484-2.00551-0.23000.h5\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.4242 - categorical_accuracy: 0.4379 - val_loss: 1.4649 - val_categorical_accuracy: 0.3533\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2506_37_23.930997/model-00005-1.42419-0.43791-1.46489-0.35333.h5\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.3972 - categorical_accuracy: 0.4150 - val_loss: 1.4035 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2506_37_23.930997/model-00006-1.39721-0.41503-1.40352-0.36667.h5\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 47s 1s/step - loss: 1.4728 - categorical_accuracy: 0.3497 - val_loss: 1.4457 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2506_37_23.930997/model-00007-1.47280-0.34967-1.44566-0.33000.h5\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 48s 1s/step - loss: 1.3237 - categorical_accuracy: 0.4477 - val_loss: 1.5148 - val_categorical_accuracy: 0.3733\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2506_37_23.930997/model-00008-1.32372-0.44771-1.51478-0.37333.h5\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.2624 - categorical_accuracy: 0.4739 - val_loss: 1.5908 - val_categorical_accuracy: 0.3633\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2506_37_23.930997/model-00009-1.26241-0.47386-1.59076-0.36333.h5\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 1.3108 - categorical_accuracy: 0.4052 - val_loss: 1.6242 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2506_37_23.930997/model-00010-1.31079-0.40523-1.62416-0.35000.h5\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.2057 - categorical_accuracy: 0.4902 - val_loss: 1.3561 - val_categorical_accuracy: 0.4767\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2506_37_23.930997/model-00011-1.20569-0.49020-1.35606-0.47667.h5\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.3024 - categorical_accuracy: 0.4575 - val_loss: 1.8034 - val_categorical_accuracy: 0.3733\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2506_37_23.930997/model-00012-1.30240-0.45752-1.80336-0.37333.h5\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 1.2143 - categorical_accuracy: 0.4804 - val_loss: 1.5705 - val_categorical_accuracy: 0.3367\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2506_37_23.930997/model-00013-1.21425-0.48039-1.57053-0.33667.h5\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 1.1946 - categorical_accuracy: 0.5850 - val_loss: 2.1818 - val_categorical_accuracy: 0.2033\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2506_37_23.930997/model-00014-1.19457-0.58497-2.18176-0.20333.h5\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 1.0990 - categorical_accuracy: 0.5784 - val_loss: 1.4956 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2506_37_23.930997/model-00015-1.09896-0.57843-1.49557-0.36667.h5\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 47s 1s/step - loss: 1.1729 - categorical_accuracy: 0.5196 - val_loss: 1.3105 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2506_37_23.930997/model-00016-1.17288-0.51961-1.31045-0.48333.h5\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.1460 - categorical_accuracy: 0.5065 - val_loss: 1.2977 - val_categorical_accuracy: 0.4533\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2506_37_23.930997/model-00017-1.14605-0.50654-1.29765-0.45333.h5\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 44s 1s/step - loss: 1.2246 - categorical_accuracy: 0.5327 - val_loss: 1.5582 - val_categorical_accuracy: 0.3267\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2506_37_23.930997/model-00018-1.22461-0.53268-1.55817-0.32667.h5\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.1858 - categorical_accuracy: 0.5654 - val_loss: 1.4918 - val_categorical_accuracy: 0.4433\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2506_37_23.930997/model-00019-1.18575-0.56536-1.49177-0.44333.h5\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.1121 - categorical_accuracy: 0.5817 - val_loss: 1.5528 - val_categorical_accuracy: 0.3967\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2506_37_23.930997/model-00020-1.11215-0.58170-1.55278-0.39667.h5\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.8969 - categorical_accuracy: 0.7157 - val_loss: 1.4216 - val_categorical_accuracy: 0.4667\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-05-2506_37_23.930997/model-00021-0.89690-0.71569-1.42158-0.46667.h5\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.9871 - categorical_accuracy: 0.6340 - val_loss: 1.8082 - val_categorical_accuracy: 0.3733\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-05-2506_37_23.930997/model-00022-0.98713-0.63399-1.80823-0.37333.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.0088 - categorical_accuracy: 0.5882 - val_loss: 1.3356 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-05-2506_37_23.930997/model-00023-1.00884-0.58824-1.33563-0.49000.h5\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.0234 - categorical_accuracy: 0.5654 - val_loss: 1.1616 - val_categorical_accuracy: 0.5433\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-05-2506_37_23.930997/model-00024-1.02344-0.56536-1.16158-0.54333.h5\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.1262 - categorical_accuracy: 0.5817 - val_loss: 1.1199 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-05-2506_37_23.930997/model-00025-1.12623-0.58170-1.11990-0.54000.h5\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 49s 1s/step - loss: 0.9588 - categorical_accuracy: 0.6373 - val_loss: 1.1180 - val_categorical_accuracy: 0.5367\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-05-2506_37_23.930997/model-00026-0.95883-0.63725-1.11800-0.53667.h5\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 51s 2s/step - loss: 1.1029 - categorical_accuracy: 0.6013 - val_loss: 1.1212 - val_categorical_accuracy: 0.5267\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-05-2506_37_23.930997/model-00027-1.10294-0.60131-1.12120-0.52667.h5\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 47s 1s/step - loss: 1.0812 - categorical_accuracy: 0.5850 - val_loss: 1.1354 - val_categorical_accuracy: 0.5133\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-05-2506_37_23.930997/model-00028-1.08116-0.58497-1.13540-0.51333.h5\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.9083 - categorical_accuracy: 0.6275 - val_loss: 1.1174 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-05-2506_37_23.930997/model-00029-0.90826-0.62745-1.11741-0.51667.h5\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 48s 1s/step - loss: 0.9370 - categorical_accuracy: 0.6340 - val_loss: 1.0899 - val_categorical_accuracy: 0.5233\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-05-2506_37_23.930997/model-00030-0.93704-0.63399-1.08995-0.52333.h5\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.8978 - categorical_accuracy: 0.6699 - val_loss: 1.0671 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-05-2506_37_23.930997/model-00031-0.89780-0.66993-1.06711-0.53333.h5\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.9402 - categorical_accuracy: 0.6471 - val_loss: 1.0601 - val_categorical_accuracy: 0.5267\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-05-2506_37_23.930997/model-00032-0.94017-0.64706-1.06010-0.52667.h5\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.9593 - categorical_accuracy: 0.6078 - val_loss: 1.0767 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-05-2506_37_23.930997/model-00033-0.95933-0.60784-1.07668-0.52000.h5\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 44s 1s/step - loss: 0.9644 - categorical_accuracy: 0.6046 - val_loss: 1.0516 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-05-2506_37_23.930997/model-00034-0.96440-0.60458-1.05156-0.53000.h5\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.9548 - categorical_accuracy: 0.6536 - val_loss: 1.0487 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-05-2506_37_23.930997/model-00035-0.95483-0.65359-1.04874-0.53333.h5\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.9252 - categorical_accuracy: 0.6340 - val_loss: 1.0480 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00036: saving model to model_init_2020-05-2506_37_23.930997/model-00036-0.92522-0.63399-1.04797-0.52000.h5\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 44s 1s/step - loss: 0.9114 - categorical_accuracy: 0.6601 - val_loss: 1.0530 - val_categorical_accuracy: 0.5033\n",
      "\n",
      "Epoch 00037: saving model to model_init_2020-05-2506_37_23.930997/model-00037-0.91145-0.66013-1.05297-0.50333.h5\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.8430 - categorical_accuracy: 0.6863 - val_loss: 1.0422 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00038: saving model to model_init_2020-05-2506_37_23.930997/model-00038-0.84295-0.68627-1.04216-0.52000.h5\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.9854 - categorical_accuracy: 0.6111 - val_loss: 1.0298 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00039: saving model to model_init_2020-05-2506_37_23.930997/model-00039-0.98542-0.61111-1.02975-0.52000.h5\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 44s 1s/step - loss: 0.8803 - categorical_accuracy: 0.6536 - val_loss: 1.0339 - val_categorical_accuracy: 0.5267\n",
      "\n",
      "Epoch 00040: saving model to model_init_2020-05-2506_37_23.930997/model-00040-0.88033-0.65359-1.03393-0.52667.h5\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.8844 - categorical_accuracy: 0.6667 - val_loss: 1.0257 - val_categorical_accuracy: 0.5267\n",
      "\n",
      "Epoch 00041: saving model to model_init_2020-05-2506_37_23.930997/model-00041-0.88442-0.66667-1.02572-0.52667.h5\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.9356 - categorical_accuracy: 0.6373 - val_loss: 1.0144 - val_categorical_accuracy: 0.5267\n",
      "\n",
      "Epoch 00042: saving model to model_init_2020-05-2506_37_23.930997/model-00042-0.93563-0.63725-1.01438-0.52667.h5\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.8981 - categorical_accuracy: 0.6830 - val_loss: 1.0084 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00043: saving model to model_init_2020-05-2506_37_23.930997/model-00043-0.89808-0.68301-1.00842-0.54000.h5\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 44s 1s/step - loss: 0.8762 - categorical_accuracy: 0.6307 - val_loss: 1.0196 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00044: saving model to model_init_2020-05-2506_37_23.930997/model-00044-0.87622-0.63072-1.01965-0.53333.h5\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.8715 - categorical_accuracy: 0.6699 - val_loss: 1.0069 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00045: saving model to model_init_2020-05-2506_37_23.930997/model-00045-0.87155-0.66993-1.00695-0.53333.h5\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.9190 - categorical_accuracy: 0.6503 - val_loss: 1.0055 - val_categorical_accuracy: 0.5433\n",
      "\n",
      "Epoch 00046: saving model to model_init_2020-05-2506_37_23.930997/model-00046-0.91902-0.65033-1.00549-0.54333.h5\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.8725 - categorical_accuracy: 0.6667 - val_loss: 1.0083 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00047: saving model to model_init_2020-05-2506_37_23.930997/model-00047-0.87252-0.66667-1.00830-0.54000.h5\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 46s 1s/step - loss: 0.8656 - categorical_accuracy: 0.6634 - val_loss: 1.0059 - val_categorical_accuracy: 0.5433\n",
      "\n",
      "Epoch 00048: saving model to model_init_2020-05-2506_37_23.930997/model-00048-0.86558-0.66340-1.00595-0.54333.h5\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 45s 1s/step - loss: 0.8721 - categorical_accuracy: 0.6634 - val_loss: 0.9975 - val_categorical_accuracy: 0.5467\n",
      "\n",
      "Epoch 00049: saving model to model_init_2020-05-2506_37_23.930997/model-00049-0.87215-0.66340-0.99752-0.54667.h5\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 47s 1s/step - loss: 0.9050 - categorical_accuracy: 0.6863 - val_loss: 1.0017 - val_categorical_accuracy: 0.5433\n",
      "\n",
      "Epoch 00050: saving model to model_init_2020-05-2506_37_23.930997/model-00050-0.90504-0.68627-1.00166-0.54333.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7aaca8eb8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the number of parameters and fiting the model\n",
    "print(\"Total Params:\", model.count_params())\n",
    "num_epochs = 50\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,\n",
    "                    verbose=1,callbacks=callbacks_list, validation_data=val_generator,validation_steps=validation_steps, \n",
    "                    class_weight=None,\n",
    "                    workers=1, initial_epoch=0,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 15 - CNN-RNN - LSTM- frame size 20, Batch size 15, epoch - 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new model by adding new extra layers to the existing model\n",
    "nb_featuremap = [8,16,32,64,128]\n",
    "nb_dense = [128,64,5]\n",
    "nb_classes = 5\n",
    "# Input\n",
    "input_shape=(nb_frames,nb_rows,nb_cols,nb_channel)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(nb_featuremap[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "## model.add(GRU(128, return_sequences=False))\n",
    "## model.add(Dense(nb_classes, activation='softmax')) \n",
    "\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.25))\n",
    "        \n",
    "model.add(Dense(nb_dense[1],activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "        \n",
    "model.add(Dense(nb_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_30 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 30, 7, 7, 64)      16448     \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 30, 3, 3, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 30, 3, 3, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 30, 3, 3, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 30, 576)           0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 30, 128)           73856     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 30, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 30, 64)            4160      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 224,661\n",
      "Trainable params: 224,533\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# using a new batch value and using Adam optimizer\n",
    "batch_size = 15\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimiser =Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "# creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# creating a new checkpoint\n",
    "model_name_15 = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name_15):\n",
    "    os.mkdir(model_name_15)\n",
    "        \n",
    "filepath = model_name_15 + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 224661\n",
      "Source path =  ./Project_data/val ; batch size = 15\n",
      "Source path =  ./Project_data/train ; batch size = 15\n",
      "Epoch 1/35\n",
      "45/45 [==============================] - 228s 5s/step - loss: 1.4272 - categorical_accuracy: 0.3270 - val_loss: 1.7484 - val_categorical_accuracy: 0.2167\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-05-2418_36_25.990496/model-00001-1.41558-0.32881-1.74838-0.21667.h5\n",
      "Epoch 2/35\n",
      "45/45 [==============================] - 47s 1s/step - loss: 1.4289 - categorical_accuracy: 0.3481 - val_loss: 2.0322 - val_categorical_accuracy: 0.2429\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-05-2418_36_25.990496/model-00002-1.42893-0.34815-2.03222-0.24286.h5\n",
      "Epoch 3/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.4298 - categorical_accuracy: 0.3852 - val_loss: 2.1547 - val_categorical_accuracy: 0.1857\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-05-2418_36_25.990496/model-00003-1.42983-0.38519-2.15466-0.18571.h5\n",
      "Epoch 4/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.4690 - categorical_accuracy: 0.3432 - val_loss: 1.4235 - val_categorical_accuracy: 0.4095\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-05-2418_36_25.990496/model-00004-1.46902-0.34321-1.42352-0.40952.h5\n",
      "Epoch 5/35\n",
      "45/45 [==============================] - 50s 1s/step - loss: 1.4485 - categorical_accuracy: 0.3704 - val_loss: 1.5585 - val_categorical_accuracy: 0.3238\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-05-2418_36_25.990496/model-00005-1.44847-0.37037-1.55853-0.32381.h5\n",
      "Epoch 6/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.4399 - categorical_accuracy: 0.3481 - val_loss: 2.8420 - val_categorical_accuracy: 0.2286\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-05-2418_36_25.990496/model-00006-1.43987-0.34815-2.84198-0.22857.h5\n",
      "Epoch 7/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.4124 - categorical_accuracy: 0.3901 - val_loss: 1.3091 - val_categorical_accuracy: 0.4667\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-05-2418_36_25.990496/model-00007-1.41241-0.39012-1.30911-0.46667.h5\n",
      "Epoch 8/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.3735 - categorical_accuracy: 0.4123 - val_loss: 1.5058 - val_categorical_accuracy: 0.3429\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-05-2418_36_25.990496/model-00008-1.37352-0.41235-1.50584-0.34286.h5\n",
      "Epoch 9/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.3224 - categorical_accuracy: 0.4074 - val_loss: 2.2182 - val_categorical_accuracy: 0.2333\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-05-2418_36_25.990496/model-00009-1.32240-0.40741-2.21818-0.23333.h5\n",
      "Epoch 10/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.3537 - categorical_accuracy: 0.4346 - val_loss: 2.4722 - val_categorical_accuracy: 0.1762\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-05-2418_36_25.990496/model-00010-1.35365-0.43457-2.47223-0.17619.h5\n",
      "Epoch 11/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.3016 - categorical_accuracy: 0.4593 - val_loss: 2.0070 - val_categorical_accuracy: 0.1476\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-05-2418_36_25.990496/model-00011-1.30163-0.45926-2.00697-0.14762.h5\n",
      "Epoch 12/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.2791 - categorical_accuracy: 0.4963 - val_loss: 2.0437 - val_categorical_accuracy: 0.2571\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-05-2418_36_25.990496/model-00012-1.27910-0.49630-2.04366-0.25714.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 13/35\n",
      "45/45 [==============================] - 47s 1s/step - loss: 1.2621 - categorical_accuracy: 0.4815 - val_loss: 1.5056 - val_categorical_accuracy: 0.4095\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-05-2418_36_25.990496/model-00013-1.26210-0.48148-1.50556-0.40952.h5\n",
      "Epoch 14/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.3261 - categorical_accuracy: 0.3975 - val_loss: 1.3439 - val_categorical_accuracy: 0.4524\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-05-2418_36_25.990496/model-00014-1.32612-0.39753-1.34389-0.45238.h5\n",
      "Epoch 15/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.3160 - categorical_accuracy: 0.4370 - val_loss: 1.2764 - val_categorical_accuracy: 0.4286\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-05-2418_36_25.990496/model-00015-1.31597-0.43704-1.27639-0.42857.h5\n",
      "Epoch 16/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.1641 - categorical_accuracy: 0.5333 - val_loss: 1.1282 - val_categorical_accuracy: 0.5143\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-05-2418_36_25.990496/model-00016-1.16415-0.53333-1.12820-0.51429.h5\n",
      "Epoch 17/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.1820 - categorical_accuracy: 0.5481 - val_loss: 1.3605 - val_categorical_accuracy: 0.4238\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-05-2418_36_25.990496/model-00017-1.18203-0.54815-1.36054-0.42381.h5\n",
      "Epoch 18/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.2463 - categorical_accuracy: 0.4593 - val_loss: 1.2213 - val_categorical_accuracy: 0.4762\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-05-2418_36_25.990496/model-00018-1.24627-0.45926-1.22129-0.47619.h5\n",
      "Epoch 19/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.2913 - categorical_accuracy: 0.4444 - val_loss: 1.1744 - val_categorical_accuracy: 0.4952\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-05-2418_36_25.990496/model-00019-1.29130-0.44444-1.17444-0.49524.h5\n",
      "Epoch 20/35\n",
      "45/45 [==============================] - 47s 1s/step - loss: 1.2585 - categorical_accuracy: 0.4519 - val_loss: 1.2996 - val_categorical_accuracy: 0.4143\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-05-2418_36_25.990496/model-00020-1.25850-0.45185-1.29960-0.41429.h5\n",
      "Epoch 21/35\n",
      "45/45 [==============================] - 51s 1s/step - loss: 1.2416 - categorical_accuracy: 0.4420 - val_loss: 1.1920 - val_categorical_accuracy: 0.5048\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-05-2418_36_25.990496/model-00021-1.24163-0.44198-1.19205-0.50476.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 22/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.1549 - categorical_accuracy: 0.5235 - val_loss: 1.2600 - val_categorical_accuracy: 0.4524\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-05-2418_36_25.990496/model-00022-1.15490-0.52346-1.26001-0.45238.h5\n",
      "Epoch 23/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.1997 - categorical_accuracy: 0.5259 - val_loss: 1.0972 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-05-2418_36_25.990496/model-00023-1.19975-0.52593-1.09721-0.53333.h5\n",
      "Epoch 24/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.2406 - categorical_accuracy: 0.4667 - val_loss: 1.3125 - val_categorical_accuracy: 0.4476\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-05-2418_36_25.990496/model-00024-1.24060-0.46667-1.31254-0.44762.h5\n",
      "Epoch 25/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.1846 - categorical_accuracy: 0.5062 - val_loss: 1.2705 - val_categorical_accuracy: 0.4381\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-05-2418_36_25.990496/model-00025-1.18458-0.50617-1.27052-0.43810.h5\n",
      "Epoch 26/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.2159 - categorical_accuracy: 0.4716 - val_loss: 1.1529 - val_categorical_accuracy: 0.5048\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-05-2418_36_25.990496/model-00026-1.21586-0.47160-1.15292-0.50476.h5\n",
      "Epoch 27/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.2423 - categorical_accuracy: 0.4617 - val_loss: 1.1445 - val_categorical_accuracy: 0.5048\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-05-2418_36_25.990496/model-00027-1.24231-0.46173-1.14452-0.50476.h5\n",
      "Epoch 28/35\n",
      "45/45 [==============================] - 50s 1s/step - loss: 1.2180 - categorical_accuracy: 0.5259 - val_loss: 1.2216 - val_categorical_accuracy: 0.4476\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-05-2418_36_25.990496/model-00028-1.21804-0.52593-1.22160-0.44762.h5\n",
      "Epoch 29/35\n",
      "45/45 [==============================] - 47s 1s/step - loss: 1.1494 - categorical_accuracy: 0.5383 - val_loss: 1.3390 - val_categorical_accuracy: 0.4333\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-05-2418_36_25.990496/model-00029-1.14944-0.53827-1.33900-0.43333.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 30/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.1624 - categorical_accuracy: 0.5235 - val_loss: 1.1993 - val_categorical_accuracy: 0.4571\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-05-2418_36_25.990496/model-00030-1.16242-0.52346-1.19930-0.45714.h5\n",
      "Epoch 31/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.2845 - categorical_accuracy: 0.4790 - val_loss: 1.2135 - val_categorical_accuracy: 0.4905\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-05-2418_36_25.990496/model-00031-1.28451-0.47901-1.21346-0.49048.h5\n",
      "Epoch 32/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.2504 - categorical_accuracy: 0.4469 - val_loss: 1.2156 - val_categorical_accuracy: 0.4476\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-05-2418_36_25.990496/model-00032-1.25036-0.44691-1.21560-0.44762.h5\n",
      "Epoch 33/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.2063 - categorical_accuracy: 0.5136 - val_loss: 1.1926 - val_categorical_accuracy: 0.5048\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-05-2418_36_25.990496/model-00033-1.20625-0.51358-1.19261-0.50476.h5\n",
      "Epoch 34/35\n",
      "45/45 [==============================] - 49s 1s/step - loss: 1.1534 - categorical_accuracy: 0.4963 - val_loss: 1.2376 - val_categorical_accuracy: 0.4762\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-05-2418_36_25.990496/model-00034-1.15344-0.49630-1.23756-0.47619.h5\n",
      "Epoch 35/35\n",
      "45/45 [==============================] - 48s 1s/step - loss: 1.1551 - categorical_accuracy: 0.5086 - val_loss: 1.1115 - val_categorical_accuracy: 0.5381\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-05-2418_36_25.990496/model-00035-1.15514-0.50864-1.11149-0.53810.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25e6f7efd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the number of parameters and fiting the model\n",
    "print(\"Total Params:\", model.count_params())\n",
    "num_epochs = 35\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,\n",
    "                    verbose=1,callbacks=callbacks_list, validation_data=val_generator,validation_steps=validation_steps, \n",
    "                    class_weight=None,\n",
    "                    workers=1, initial_epoch=0,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
